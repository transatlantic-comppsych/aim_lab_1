---
title: "Model 3 (with Depression as an interaction effect)"
format: html
editor: visual
---

```{r}
# Load necessary libraries
library(dplyr)
library(purrr)
library(brms)
library(ggplot2)
library(Metrics)

#This gamma value was the best fitted
gamma <- 0.96



# Add necessary columns to the dataframe
data <- data %>%
  mutate(
        weighted_cumulative_exp_exp= NA)

# Loop over each participant
for (id in unique(data$Random_ID)) {
  # Extract the subset of data for the current participant
  subset_data <- data %>% filter(Random_ID == id)
  
  # Initialize values for each participant
  subset_data$weighted_cumulative_exp_exp <- numeric(nrow(subset_data))


  # Loop over each trial for the current participant
  for (t in 1:nrow(subset_data)) {

    # Calculate cumulative weighted sums
    weighted_sum_exp_exp <- sum(sapply(1:t, function(j) gamma^(t - j) * subset_data$Response_pred[j]))


    # Update subset data for the current trial
    subset_data$weighted_cumulative_exp_exp[t] <- weighted_sum_exp_exp


  }
  
  # Merge subset data back into the main data
  data[data$Random_ID == id, c( "weighted_cumulative_exp_exp")] <-
    subset_data[, c("weighted_cumulative_exp_exp")]
}

# Print the data to inspect results
print(head(data))

data$weighted_cumulative_exp_exp <- scale(data$weighted_cumulative_exp_exp)
data$Response_fdbk <- scale(data$Response_fdbk)
data$Response_Ax<- scale(data$Response_Ax)
data$Response_H<- scale(data$Response_H)


Model_3_anx <- lmerTest::lmer(
  Response_Ax ~ weighted_cumulative_exp_exp*Depression_score  +  Response_fdbk*Depression_score+ (1 + weighted_cumulative_exp_exp + Response_fdbk  | Random_ID),
  data = data)

Model_3_mood <- lmerTest::lmer(
  Response_H ~ weighted_cumulative_exp_exp*Depression_score  +  Response_fdbk*Depression_score+ (1 + weighted_cumulative_exp_exp + Response_fdbk  | Random_ID),
  data = data)


summary(Model_3_anx)
summary(Model_3_mood)



# Random effects per participant
rand_eff <- ranef(Model_3_mood)$Random_ID
rand_eff$Random_ID <- rownames(rand_eff)

# Merge with Depression_score (as before)
dep_scores <- data[!duplicated(data$Random_ID), c("Random_ID", "Depression_score")]


merged_df <- merge(rand_eff, dep_scores, by = "Random_ID")

# Add fixed slopes
fe <- fixef(Model_3_mood)

# Calculate full participant-specific slopes:
merged_df$eff_slope_wce <- fe["weighted_cumulative_exp_exp"] +
                           merged_df$weighted_cumulative_exp_exp

merged_df$eff_slope_feedback <- fe["Response_fdbk"] +
                                merged_df$Response_fdbk


ggplot(merged_df, aes(x = Depression_score, y = eff_slope_wce)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "Participant-Specific Slopes for weighted_cumulative_exp_exp",
       x = "Depression_score", y = "Effective Slope")

 ggplot(merged_df, aes(x = Depression_score, y = eff_slope_feedback)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "Participant-Specific Slopes for Response_fdbk",
       x = "Depression_score", y = "Effective Slope")
cor.test(merged_df$eff_slope_feedback, merged_df$Depression_score)

ggplot(merged_df, aes(x = Depression_score, y = eff_slope_feedback, color = Depression_Threshold)) +
  geom_point(size = 3, alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  scale_color_manual(values = c("Below cutoff" = "steelblue", "Above cutoff" = "firebrick")) +
  labs(title = "Effective Slope of Response_fdbk vs Depression_score",
       x = "Depression_score",
       y = "Effective Slope",
       color = "Depression Group") +
  theme_minimal()

```

```{r}
#ADD DEPRESSION MAIN EFFECT & SCALED PREDICTOR AND OUTCOME VARIABLES
########################################## For Anxiety ########################################
library(rstan)
library(dplyr)
library(ggplot2)

data_pilot <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Extracted_data/pilot_21_variables.csv")

data_18_25_pro <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/final_df_18_25_Pro_with_stresslevels.csv")

data_26_45_pro <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/final_df_26_45_Pro_with_stresslevels.csv")

data_14_18 <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/final_df_students_with_stresslevels.csv")

data_18_25_com <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/final_df_18_25_com_with_stresslevels.csv")

data_merged <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/surprise_task_merged_data.csv")

data <- data_merged

#Note: Depression already scaled for merged dataset
data[, c("Response_fdbk", "Response_pred", "Response_H", "mini_SPIN_total", "Response_Ax")] <- scale(data[, c("Response_fdbk", "Response_pred", "Response_H", "mini_SPIN_total", "Response_Ax")])

N <- length(unique(data$Random_ID))  # Number of participants
T <- 48  # Trials per participant
Depression_vector <- tapply(data$Depression_score, data$Random_ID, function(x) unique(x)[1])

# Create the stan_data list
stan_data <- list(
  N = N,
  T = T,
  Tsubj = rep(48, N),
  Response_fdbk = matrix(data$Response_fdbk, nrow = N, ncol = T, byrow = TRUE),
  Response_Ax = matrix(data$Response_Ax, nrow = N, ncol = T, byrow = TRUE),
  Response_pred = matrix(data$Response_pred, nrow = N, ncol = T, byrow = TRUE),
  Depression_score = as.vector(Depression_vector)  # vector of length N
)



weighted_exp_outcome_anx_Dep_main_effect <- "
data {
  int<lower=1> N; // Number of Participants
  int<lower=1> T; // Trials per subject
  int<lower=1, upper=T> Tsubj[N]; 
  array[N, T] real Response_pred;
  array[N, T] real Response_Ax;
  array[N, T] real Response_fdbk;
  vector[N] Depression_score;
}
parameters {
  real intercept;
  real w1_mu;
  real w2_mu;
  real gam_mu;
  real sig_mu;

  // Regression weights for Depression_score
  real beta_w0;
  real beta_w1;
  real beta_w2;
  real beta_gam;
  real beta_sig;
  real beta_Dep;  // Direct effect of Depression_score

  real<lower=0> sigma_w0;
  vector<lower=0>[4] sigma;

  vector[N] w0_pr;
  vector[N] w1_pr;
  vector[N] w2_pr;
  vector[N] gam_pr;
  vector[N] sig_pr;
}
transformed parameters {
  vector[N] w0;
  vector[N] w1;
  vector[N] w2;
  vector<lower=0, upper=1>[N] gam;
  vector<lower=0>[N] sig;

  for (i in 1:N) {
    w0[i]  = intercept + beta_w0 * Depression_score[i] + sigma_w0 * w0_pr[i];
    w1[i]  = w1_mu + beta_w1 * Depression_score[i] + sigma[1] * w1_pr[i];
    w2[i]  = w2_mu + beta_w2 * Depression_score[i] + sigma[2] * w2_pr[i];

    gam[i] = Phi_approx(gam_mu + beta_gam * Depression_score[i] + sigma[3] * gam_pr[i]);
    sig[i] = exp(sig_mu + beta_sig * Depression_score[i] + sigma[4] * sig_pr[i]);
  }
}
model {
  // Priors adjusted for standardized data
  intercept  ~ normal(0, 1);
  w1_mu      ~ normal(0, 0.5);
  w2_mu      ~ normal(0, 0.5);
  gam_mu     ~ normal(0, 0.5);
  sig_mu     ~ normal(0, 0.5);

  beta_w0  ~ normal(0, 0.5);
  beta_w1  ~ normal(0, 0.5);
  beta_w2  ~ normal(0, 0.5);
  beta_gam ~ normal(0, 0.5);
  beta_sig ~ normal(0, 0.5);
  beta_Dep  ~ normal(0, 0.5);  

  sigma_w0 ~ normal(0, 1);
  sigma    ~ normal(0, 0.1);

  w0_pr  ~ normal(0, 1.0);
  w1_pr  ~ normal(0, 1.0);
  w2_pr  ~ normal(0, 1.0);
  gam_pr ~ normal(0, 1.0);
  sig_pr ~ normal(0, 1.0);

  for (i in 1:N) {
    real ev_sum = 0;
    for (t in 1:Tsubj[i]) {
      Response_Ax[i, t] ~ normal(w0[i] + w1[i] * ev_sum + w2[i] * Response_fdbk[i, t] + beta_Dep * Depression_score[i], sig[i]);
      ev_sum += Response_pred[i, t];
      ev_sum *= gam[i];
    }
  }
}
generated quantities {
  real mu_w0;
  real mu_w1;
  real mu_w2;
  real<lower=0, upper=1> mu_gam;
  real<lower=0> mu_sig;
  real log_lik[N];
  real y_pred[N, T];

  for (i in 1:N) {
    for (t in 1:T) {
      y_pred[i, t] = -1;
    }
  }

  mu_w0  = intercept;
  mu_w1  = w1_mu;
  mu_w2  = w2_mu;
  mu_gam = Phi_approx(gam_mu);
  mu_sig = exp(sig_mu);

  for (i in 1:N) {
    real ev_sum = 0;
    log_lik[i] = 0;
    for (t in 1:Tsubj[i]) {
      real mu = w0[i] + w1[i] * ev_sum + w2[i] * Response_fdbk[i, t] + beta_Dep * Depression_score[i];
      log_lik[i] += normal_lpdf(Response_Ax[i, t] | mu, sig[i]);
      y_pred[i, t] = normal_rng(mu, sig[i]);

      ev_sum += Response_pred[i, t];
      ev_sum *= gam[i];
    }
  }
}

"

```

```{r}

# Compile and Fit the Model
weighted_exp_outcome_anx_Dep_main_effect_fit <- stan(model_code = weighted_exp_outcome_anx_Dep_main_effect, data = stan_data, iter = 4000, warmup = 2000, chains = 4, seed = 123, cores = 4, control = list(adapt_delta = 0.95,
  max_treedepth = 10))

options(max.print = 99999)
# Print results
print(weighted_exp_outcome_anx_Dep_main_effect_fit)

# Save the model output as an .rds file
saveRDS(weighted_exp_outcome_anx_Dep_main_effect_fit, file = "weighted_exp_outcome_anx_Dep_main_effect_fit.rds")

```

```{r}


# Plot results
traceplot(weighted_exp_outcome_anx_Dep_main_effect_fit)

# Extract posterior samples
posterior_samples <- rstan::extract(weighted_exp_outcome_anx_Dep_main_effect_fit)

library(ggplot2)
library(dplyr)
library(tidyr)


# 2. Calculate the estimated Response_Ax for each participant
# Generate the estimated Response_Ax from posterior predictive distribution
y_pred <- posterior_samples$y_pred


# Extract log-likelihood per participant (N-length vector)
log_lik_vector <- rstan::extract(weighted_exp_outcome_anx_Dep_main_effect_fit, pars = "log_lik")$log_lik  # Dimensions: [S, N] (S = posterior samples)

# Compute LOO-CV
library(loo)
loo_result <- loo(log_lik_vector)
print(loo_result)
dim(log_lik_vector)
library(loo)

# Compute WAIC
waic_result <- waic(log_lik_vector)
print(waic_result)



# Extract the posterior samples
posterior_samples <- rstan::extract(weighted_exp_outcome_anx_Dep_main_effect_fit)

# Predicted values (posterior predictive distribution)
y_pred <- posterior_samples$y_pred
# Load required package
library(matrixStats)

# Compute mean predicted values (posterior mean)
y_pred_mean <- apply(y_pred, c(2,3), mean)  # Mean across posterior samples

# Compute MSE
mse <- mean((y_pred_mean - stan_data$Response_Ax)^2)

# Compute MAE
mae <- mean(abs(y_pred_mean -  stan_data$Response_Ax))

print(paste("MSE:", mse))
print(paste("MAE:", mae))


y_pred_mean <- apply(posterior_samples$y_pred, c(2, 3), mean) 
y_pred_df <- as.data.frame(y_pred_mean)
colnames(y_pred_df) <- paste0("Trial_", 1:T)
y_pred_df$Random_ID <- unique(data$Random_ID)


# Convert Response_Ax to matrix and then to a data frame
Response_Ax_matrix <- matrix(data$Response_Ax, nrow = N, ncol = T, byrow = TRUE)
Response_Ax_df <- as.data.frame(Response_Ax_matrix)
colnames(Response_Ax_df) <- paste0("Trial_", 1:T)
Response_Ax_df$Random_ID <- unique(data$Random_ID)

# Reshape data into long format
y_pred_long <- pivot_longer(y_pred_df, cols = starts_with("Trial_"), names_to = "Trial", values_to = "Predicted_Response")
Response_Ax_long <- pivot_longer(Response_Ax_df, cols = starts_with("Trial_"), names_to = "Trial", values_to = "Actual_Response")

# Merge actual and predicted data
plot_data <- left_join(Response_Ax_long, y_pred_long, by = c("Random_ID", "Trial"))

# Convert Trial to numeric
plot_data$Trial <- as.numeric(gsub("Trial_", "", plot_data$Trial))



# Plot individual real data and fitted curve for each participant using ggplot2
ggplot(plot_data, aes(x = Trial)) +
  geom_line(aes(y = Actual_Response), color = "blue", size = 1) + 
  geom_line(aes(y = Predicted_Response), color = "red", size = 1) +
  facet_wrap(~ Random_ID, scales = "free_y") +
  labs(title = "Real Data and Fitted Curve per Participant",
       x = "Trial Number",
       y = "Anxiety") +
  ylim(-3,3)
  theme_minimal()

  
library(bayesplot)
y_obs <- stan_data$Response_Ax
# Select a subset of posterior draws for plotting
set.seed(123)
draws_to_plot <- sample(1:dim(y_pred)[1], 20)  # e.g. 20 random posterior draws
y_pred_subset <- y_pred[draws_to_plot,,]        # Subset of y_rep

# Flatten y_obs for histogram comparison
y_obs_flat <- as.vector(y_obs)

# Convert y_rep_subset into a matrix: draws x (N*T)
y_pred_matrix <- apply(y_pred_subset, 1, function(mat) as.vector(t(mat)))
y_pred_matrix <- t(y_pred_matrix)  # make it draws x obs

# Now plot
color_scheme_set("blue")
ppc_hist(y_obs_flat, y_pred_matrix[1:8, ])  # show 8 histograms for example

```

```{r}

posterior <- rstan::extract(weighted_exp_outcome_anx_Dep_main_effect_fit)

Dep_info <- data %>%
  group_by(Random_ID) %>%
  summarise(    
    Dep = first(Depression_score),
    Dep_Threshold = first(Depression_Threshold)
  ) %>%
  arrange(Random_ID)
group_labels <- ifelse(Dep_info$Dep_Threshold == 1, "High Dep", "Low Dep")
low_Dep_vals  <- Dep_info$Dep[Dep_info$Dep_Threshold == 0]
high_Dep_vals <- Dep_info$Dep[Dep_info$Dep_Threshold == 1]


# Number of posterior samples
n_samples <- length(posterior$intercept)

# For each group, calculate the parameter across participants and average
w0_low  <- rowMeans(matrix(posterior$intercept, nrow = n_samples, ncol = length(low_Dep_vals)) +
                    posterior$beta_w0 %o% low_Dep_vals)

w0_high <- rowMeans(matrix(posterior$intercept, nrow = n_samples, ncol = length(high_Dep_vals)) +
                    posterior$beta_w0 %o% high_Dep_vals)

# Same for w1
w1_low  <- rowMeans(matrix(posterior$w1_mu, nrow = n_samples, ncol = length(low_Dep_vals)) +
                    posterior$beta_w1 %o% low_Dep_vals)

w1_high <- rowMeans(matrix(posterior$w1_mu, nrow = n_samples, ncol = length(high_Dep_vals)) +
                    posterior$beta_w1 %o% high_Dep_vals)

# Same for w2
w2_low  <- rowMeans(matrix(posterior$w2_mu, nrow = n_samples, ncol = length(low_Dep_vals)) +
                    posterior$beta_w2 %o% low_Dep_vals)

w2_high <- rowMeans(matrix(posterior$w2_mu, nrow = n_samples, ncol = length(high_Dep_vals)) +
                    posterior$beta_w2 %o% high_Dep_vals)

# Gamma (use pnorm)
gamma_low  <- rowMeans(pnorm(matrix(posterior$gam_mu, nrow = n_samples, ncol = length(low_Dep_vals)) +
                             posterior$beta_gam %o% low_Dep_vals))

gamma_high <- rowMeans(pnorm(matrix(posterior$gam_mu, nrow = n_samples, ncol = length(high_Dep_vals)) +
                             posterior$beta_gam %o% high_Dep_vals))

# Sigma (use exp)
sigma_low  <- rowMeans(exp(matrix(posterior$sig_mu, nrow = n_samples, ncol = length(low_Dep_vals)) +
                           posterior$beta_sig %o% low_Dep_vals))

sigma_high <- rowMeans(exp(matrix(posterior$sig_mu, nrow = n_samples, ncol = length(high_Dep_vals)) +
                           posterior$beta_sig %o% high_Dep_vals))

# Helper function for mean and 95% CI
summarize_param <- function(low, high) {
  low_mean  <- mean(low)
  high_mean <- mean(high)
  diff <- high - low
  diff_mean <- mean(diff)
  
  low_CI  <- quantile(low, probs = c(0.025, 0.975))
  high_CI <- quantile(high, probs = c(0.025, 0.975))
  diff_CI <- quantile(diff, probs = c(0.025, 0.975))
  
  data.frame(
    `Low Dep Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", low_mean,  low_CI[1],  low_CI[2]),
    `High Dep Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", high_mean, high_CI[1], high_CI[2]),
    `High - Low Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", diff_mean, diff_CI[1], diff_CI[2])
  )
}

# Generate summary table
summary_table <- rbind(
  summarize_param(w0_low, w0_high),
  summarize_param(w1_low, w1_high),
  summarize_param(w2_low, w2_high),
  summarize_param(gamma_low, gamma_high),
  summarize_param(sigma_low, sigma_high)
)

summary_table <- cbind(Parameter = c("w0", "w1", "w2", "gamma", "sigma"), summary_table)

# Show table
print(summary_table, row.names = FALSE)

# Prepare for plotting
posterior_df <- data.frame(
  w0_low, w0_high,
  w1_low, w1_high,
  w2_low, w2_high,
  gamma_low, gamma_high,
  sigma_low, sigma_high
)

plot_data <- posterior_df %>%
  pivot_longer(cols = everything(), names_to = "param", values_to = "value") %>%
  mutate(
    group = ifelse(grepl("_low", param), "Low Dep", "High Dep"),
    param_clean = gsub("_(low|high)", "", param)
  )

# Calculate group means for vertical lines
vlines <- plot_data %>%
  group_by(param_clean, group) %>%
  summarise(mean_val = mean(value), .groups = "drop")

# Plot posterior densities with vertical lines
ggplot(plot_data, aes(x = value, fill = group, color = group)) +
  geom_density(alpha = 0.4, size = 0.8) +
  geom_vline(data = vlines, aes(xintercept = mean_val, color = group),
             linetype = "dashed", size = 0.7) +
  scale_fill_manual(values = c("Low Dep" = "blue", "High Dep" = "red")) +
  scale_color_manual(values = c("Low Dep" = "blue", "High Dep" = "red")) +
  facet_wrap(~ param_clean, scales = "free", ncol = 2) +
  theme_minimal(base_size = 14) +
  labs(title = paste("Posterior Distributions of Parameters by Dep Group (Cutoff:", sa_cutoff, ")"),
       x = "Parameter Value", y = "Density")






# Compute means per participant
w0_mean   <- apply(posterior$w0, 2, mean)
w1_mean   <- apply(posterior$w1, 2, mean)
w2_mean   <- apply(posterior$w2, 2, mean)
gam_mean  <- apply(posterior$gam, 2, mean)
sig_mean  <- apply(posterior$sig, 2, mean)

# Assuming SA scores are stored like this:
Dep_scores <- data %>%
  group_by(Random_ID) %>%
  summarise(Dep = first(Depression_score)) %>%
  arrange(Random_ID)

# Combine into a clean dataframe
param_df <- data.frame(
  ID = unique(data$Random_ID),
  Dep = Dep_scores$Dep,
  w0 = w0_mean,
  w1 = w1_mean,
  w2 = w2_mean,
  gamma = gam_mean,
  sigma = sig_mean
)

library(ggplot2)

# Function to create correlation plots
plot_correlation <- function(df, param, color = "#3366CC") {
  ggplot(df, aes_string(x = "Dep", y = param)) +
    geom_point(color = color, alpha = 0.7, size = 3) +
    geom_smooth(method = "lm", se = TRUE, color = "black", linetype = "dashed") +
    labs(
      x = "Depression Score",
      y = paste0("Mean Posterior of ", param),
      title = paste("Dep vs", param)
    ) +
    theme_minimal(base_size = 14)
}

# Plot examples
plot_correlation(param_df, "w0")
plot_correlation(param_df, "w1")
plot_correlation(param_df, "w2")
plot_correlation(param_df, "gamma")
plot_correlation(param_df, "sigma")

# Function to compute r and p for each parameter
get_corr_stats <- function(x, y) {
  test <- cor.test(x, y, method = "pearson")
  data.frame(
    r = round(test$estimate, 3),
    p_value = round(test$p.value, 4)
  )
}

# Apply to each parameter vs SA
corr_results <- rbind(
  get_corr_stats(param_df$Dep, param_df$w0),
  get_corr_stats(param_df$Dep, param_df$w1),
  get_corr_stats(param_df$Dep, param_df$w2),
  get_corr_stats(param_df$Dep, param_df$gamma),
  get_corr_stats(param_df$Dep, param_df$sigma)
)

# Label the rows
rownames(corr_results) <- c("w0", "w1", "w2", "gamma", "sigma")

# View results
print(corr_results)


```

```{r}
#ADD SOCIAL ANXIETY MAIN EFFECT & SCALED PREDICTOR AND OUTCOME VARIABLES
########################################## For MOOD ########################################
library(rstan)
library(dplyr)
library(ggplot2)

data_pilot <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Extracted_data/pilot_21_variables.csv")

data_18_25_pro <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/final_df_18_25_Pro_with_stresslevels.csv")

data_26_45_pro <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/final_df_26_45_Pro_with_stresslevels.csv")

data_14_18 <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/final_df_students_with_stresslevels.csv")

data_18_25_com <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/final_df_18_25_com_with_stresslevels.csv")

data_merged <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/surprise_task_merged_data.csv")
  
data <- data_merged

#Note: Depression already scaled for merged dataset
data[, c("Response_fdbk", "Response_pred", "Response_H", "mini_SPIN_total", "Response_Ax")] <- scale(data[, c("Response_fdbk", "Response_pred", "Response_H", "mini_SPIN_total", "Response_Ax")])

N <- length(unique(data$Random_ID))  # Number of participants
T <- 48  # Trials per participant
Depression_vector <- tapply(data$Depression_score, data$Random_ID, function(x) unique(x)[1])

# Create the stan_data list
stan_data <- list(
  N = N,
  T = T,
  Tsubj = rep(48, N),
  Response_fdbk = matrix(data$Response_fdbk, nrow = N, ncol = T, byrow = TRUE),
  Response_H = matrix(data$Response_H, nrow = N, ncol = T, byrow = TRUE),
  Response_pred = matrix(data$Response_pred, nrow = N, ncol = T, byrow = TRUE),
  Depression_score = as.vector(Depression_vector)  # vector of length N
)



weighted_exp_outcome_mood_Dep_main_effect <- "
data {
  int<lower=1> N; // Number of Participants
  int<lower=1> T; // Trials per subject
  int<lower=1, upper=T> Tsubj[N]; 
  array[N, T] real Response_pred;
  array[N, T] real Response_H;
  array[N, T] real Response_fdbk;
  vector[N] Depression_score;
}
parameters {
  real intercept;
  real w1_mu;
  real w2_mu;
  real gam_mu;
  real sig_mu;

  // Regression weights for Depression_score
  real beta_w0;
  real beta_w1;
  real beta_w2;
  real beta_gam;
  real beta_sig;
  real beta_Dep;  // Direct effect of Depression_score

  real<lower=0> sigma_w0;
  vector<lower=0>[4] sigma;

  vector[N] w0_pr;
  vector[N] w1_pr;
  vector[N] w2_pr;
  vector[N] gam_pr;
  vector[N] sig_pr;
}
transformed parameters {
  vector[N] w0;
  vector[N] w1;
  vector[N] w2;
  vector<lower=0, upper=1>[N] gam;
  vector<lower=0>[N] sig;

  for (i in 1:N) {
    w0[i]  = intercept + beta_w0 * Depression_score[i] + sigma_w0 * w0_pr[i];
    w1[i]  = w1_mu + beta_w1 * Depression_score[i] + sigma[1] * w1_pr[i];
    w2[i]  = w2_mu + beta_w2 * Depression_score[i] + sigma[2] * w2_pr[i];

    gam[i] = Phi_approx(gam_mu + beta_gam * Depression_score[i] + sigma[3] * gam_pr[i]);
    sig[i] = exp(sig_mu + beta_sig * Depression_score[i] + sigma[4] * sig_pr[i]);
  }
}
model {
  // Priors adjusted for standardized data
  intercept  ~ normal(0, 1);
  w1_mu      ~ normal(0, 0.5);
  w2_mu      ~ normal(0, 0.5);
  gam_mu     ~ normal(0, 0.5);
  sig_mu     ~ normal(0, 0.5);

  beta_w0  ~ normal(0, 0.5);
  beta_w1  ~ normal(0, 0.5);
  beta_w2  ~ normal(0, 0.5);
  beta_gam ~ normal(0, 0.5);
  beta_sig ~ normal(0, 0.5);
  beta_Dep  ~ normal(0, 0.5);  

  sigma_w0 ~ normal(0, 1);
  sigma    ~ normal(0, 0.1);

  w0_pr  ~ normal(0, 1.0);
  w1_pr  ~ normal(0, 1.0);
  w2_pr  ~ normal(0, 1.0);
  gam_pr ~ normal(0, 1.0);
  sig_pr ~ normal(0, 1.0);

  for (i in 1:N) {
    real ev_sum = 0;
    for (t in 1:Tsubj[i]) {
      Response_H[i, t] ~ normal(w0[i] + w1[i] * ev_sum + w2[i] * Response_fdbk[i, t] + beta_Dep * Depression_score[i], sig[i]);
      ev_sum += Response_pred[i, t];
      ev_sum *= gam[i];
    }
  }
}
generated quantities {
  real mu_w0;
  real mu_w1;
  real mu_w2;
  real<lower=0, upper=1> mu_gam;
  real<lower=0> mu_sig;
  real log_lik[N];
  real y_pred[N, T];

  for (i in 1:N) {
    for (t in 1:T) {
      y_pred[i, t] = -1;
    }
  }

  mu_w0  = intercept;
  mu_w1  = w1_mu;
  mu_w2  = w2_mu;
  mu_gam = Phi_approx(gam_mu);
  mu_sig = exp(sig_mu);

  for (i in 1:N) {
    real ev_sum = 0;
    log_lik[i] = 0;
    for (t in 1:Tsubj[i]) {
      real mu = w0[i] + w1[i] * ev_sum + w2[i] * Response_fdbk[i, t] + beta_Dep * Depression_score[i];
      log_lik[i] += normal_lpdf(Response_H[i, t] | mu, sig[i]);
      y_pred[i, t] = normal_rng(mu, sig[i]);

      ev_sum += Response_pred[i, t];
      ev_sum *= gam[i];
    }
  }
}

"

```

```{r}
# Compile and Fit the Model
weighted_exp_outcome_mood_Dep_main_effect_fit <- stan(model_code = weighted_exp_outcome_mood_Dep_main_effect, data = stan_data, iter = 5000, warmup = 3000, chains = 4, seed = 123, cores = 4, control = list(adapt_delta = 0.95,
  max_treedepth = 10))

options(max.print = 99999)
# Print results
print(weighted_exp_outcome_mood_Dep_main_effect_fit)

# Save the model output as an .rds file
saveRDS(weighted_exp_outcome_mood_Dep_main_effect_fit, file = "weighted_exp_outcome_mood_Dep_main_effect_fit.rds")

```

```{r}


# Plot results
traceplot(weighted_exp_outcome_mood_Dep_main_effect_fit)

# Extract posterior samples
posterior_samples <- rstan::extract(weighted_exp_outcome_mood_Dep_main_effect_fit)

library(ggplot2)
library(dplyr)
library(tidyr)


# 2. Calculate the estimated Response_Ax for each participant
# Generate the estimated Response_Ax from posterior predictive distribution
y_pred <- posterior_samples$y_pred


# Extract log-likelihood per participant (N-length vector)
log_lik_vector <- rstan::extract(weighted_exp_outcome_mood_Dep_main_effect_fit, pars = "log_lik")$log_lik  # Dimensions: [S, N] (S = posterior samples)

# Compute LOO-CV
library(loo)
loo_result <- loo(log_lik_vector)
print(loo_result)
dim(log_lik_vector)
library(loo)

# Compute WAIC
waic_result <- waic(log_lik_vector)
print(waic_result)



# Extract the posterior samples
posterior_samples <- rstan::extract(weighted_exp_outcome_mood_Dep_main_effect_fit)

# Predicted values (posterior predictive distribution)
y_pred <- posterior_samples$y_pred
# Load required package
library(matrixStats)

# Compute mean predicted values (posterior mean)
y_pred_mean <- apply(y_pred, c(2,3), mean)  # Mean across posterior samples

# Compute MSE
mse <- mean((y_pred_mean - stan_data$Response_H)^2)

# Compute MAE
mae <- mean(abs(y_pred_mean -  stan_data$Response_H))

print(paste("MSE:", mse))
print(paste("MAE:", mae))


y_pred_mean <- apply(posterior_samples$y_pred, c(2, 3), mean) 
y_pred_df <- as.data.frame(y_pred_mean)
colnames(y_pred_df) <- paste0("Trial_", 1:T)
y_pred_df$Random_ID <- unique(data$Random_ID)


# Convert Response_Ax to matrix and then to a data frame
Response_H_matrix <- matrix(data$Response_H, nrow = N, ncol = T, byrow = TRUE)
Response_H_df <- as.data.frame(Response_Ax_matrix)
colnames(Response_H_df) <- paste0("Trial_", 1:T)
Response_H_df$Random_ID <- unique(data$Random_ID)

# Reshape data into long format
y_pred_long <- pivot_longer(y_pred_df, cols = starts_with("Trial_"), names_to = "Trial", values_to = "Predicted_Response")
Response_H_long <- pivot_longer(Response_H_df, cols = starts_with("Trial_"), names_to = "Trial", values_to = "Actual_Response")

# Merge actual and predicted data
plot_data <- left_join(Response_H_long, y_pred_long, by = c("Random_ID", "Trial"))

# Convert Trial to numeric
plot_data$Trial <- as.numeric(gsub("Trial_", "", plot_data$Trial))



# Plot individual real data and fitted curve for each participant using ggplot2
ggplot(plot_data, aes(x = Trial)) +
  geom_line(aes(y = Actual_Response), color = "blue", size = 1) + 
  geom_line(aes(y = Predicted_Response), color = "red", size = 1) +
  facet_wrap(~ Random_ID, scales = "free_y") +
  labs(title = "Real Data and Fitted Curve per Participant",
       x = "Trial Number",
       y = "Mood") +
  ylim(-3,3)
  theme_minimal()

  
library(bayesplot)
y_obs <- stan_data$Response_H
# Select a subset of posterior draws for plotting
set.seed(123)
draws_to_plot <- sample(1:dim(y_pred)[1], 20)  # e.g. 20 random posterior draws
y_pred_subset <- y_pred[draws_to_plot,,]        # Subset of y_rep

# Flatten y_obs for histogram comparison
y_obs_flat <- as.vector(y_obs)

# Convert y_rep_subset into a matrix: draws x (N*T)
y_pred_matrix <- apply(y_pred_subset, 1, function(mat) as.vector(t(mat)))
y_pred_matrix <- t(y_pred_matrix)  # make it draws x obs

# Now plot
color_scheme_set("blue")
ppc_hist(y_obs_flat, y_pred_matrix[1:8, ])  # show 8 histograms for example

```

```{r}
posterior <- rstan::extract(weighted_exp_outcome_mood_Dep_main_effect_fit)

Dep_info <- data %>%
  group_by(Random_ID) %>%
  summarise(    
    Dep = first(Depression_score),
    Dep_Threshold = first(Depression_Threshold)
  ) %>%
  arrange(Random_ID)
group_labels <- ifelse(Dep_info$Dep_Threshold == 1, "High Dep", "Low Dep")
low_Dep_vals  <- Dep_info$Dep[Dep_info$Dep_Threshold == 0]
high_Dep_vals <- Dep_info$Dep[Dep_info$Dep_Threshold == 1]


# Number of posterior samples
n_samples <- length(posterior$intercept)

# For each group, calculate the parameter across participants and average
w0_low  <- rowMeans(matrix(posterior$intercept, nrow = n_samples, ncol = length(low_Dep_vals)) +
                    posterior$beta_w0 %o% low_Dep_vals)

w0_high <- rowMeans(matrix(posterior$intercept, nrow = n_samples, ncol = length(high_Dep_vals)) +
                    posterior$beta_w0 %o% high_Dep_vals)

# Same for w1
w1_low  <- rowMeans(matrix(posterior$w1_mu, nrow = n_samples, ncol = length(low_Dep_vals)) +
                    posterior$beta_w1 %o% low_Dep_vals)

w1_high <- rowMeans(matrix(posterior$w1_mu, nrow = n_samples, ncol = length(high_Dep_vals)) +
                    posterior$beta_w1 %o% high_Dep_vals)

# Same for w2
w2_low  <- rowMeans(matrix(posterior$w2_mu, nrow = n_samples, ncol = length(low_Dep_vals)) +
                    posterior$beta_w2 %o% low_Dep_vals)

w2_high <- rowMeans(matrix(posterior$w2_mu, nrow = n_samples, ncol = length(high_Dep_vals)) +
                    posterior$beta_w2 %o% high_Dep_vals)

# Gamma (use pnorm)
gamma_low  <- rowMeans(pnorm(matrix(posterior$gam_mu, nrow = n_samples, ncol = length(low_Dep_vals)) +
                             posterior$beta_gam %o% low_Dep_vals))

gamma_high <- rowMeans(pnorm(matrix(posterior$gam_mu, nrow = n_samples, ncol = length(high_Dep_vals)) +
                             posterior$beta_gam %o% high_Dep_vals))

# Sigma (use exp)
sigma_low  <- rowMeans(exp(matrix(posterior$sig_mu, nrow = n_samples, ncol = length(low_Dep_vals)) +
                           posterior$beta_sig %o% low_Dep_vals))

sigma_high <- rowMeans(exp(matrix(posterior$sig_mu, nrow = n_samples, ncol = length(high_Dep_vals)) +
                           posterior$beta_sig %o% high_Dep_vals))

# Helper function for mean and 95% CI
summarize_param <- function(low, high) {
  low_mean  <- mean(low)
  high_mean <- mean(high)
  diff <- high - low
  diff_mean <- mean(diff)
  
  low_CI  <- quantile(low, probs = c(0.025, 0.975))
  high_CI <- quantile(high, probs = c(0.025, 0.975))
  diff_CI <- quantile(diff, probs = c(0.025, 0.975))
  
  data.frame(
    `Low Dep Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", low_mean,  low_CI[1],  low_CI[2]),
    `High Dep Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", high_mean, high_CI[1], high_CI[2]),
    `High - Low Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", diff_mean, diff_CI[1], diff_CI[2])
  )
}

# Generate summary table
summary_table <- rbind(
  summarize_param(w0_low, w0_high),
  summarize_param(w1_low, w1_high),
  summarize_param(w2_low, w2_high),
  summarize_param(gamma_low, gamma_high),
  summarize_param(sigma_low, sigma_high)
)

summary_table <- cbind(Parameter = c("w0", "w1", "w2", "gamma", "sigma"), summary_table)

# Show table
print(summary_table, row.names = FALSE)

# Prepare for plotting
posterior_df <- data.frame(
  w0_low, w0_high,
  w1_low, w1_high,
  w2_low, w2_high,
  gamma_low, gamma_high,
  sigma_low, sigma_high
)

plot_data <- posterior_df %>%
  pivot_longer(cols = everything(), names_to = "param", values_to = "value") %>%
  mutate(
    group = ifelse(grepl("_low", param), "Low Dep", "High Dep"),
    param_clean = gsub("_(low|high)", "", param)
  )

# Calculate group means for vertical lines
vlines <- plot_data %>%
  group_by(param_clean, group) %>%
  summarise(mean_val = mean(value), .groups = "drop")

# Plot posterior densities with vertical lines
ggplot(plot_data, aes(x = value, fill = group, color = group)) +
  geom_density(alpha = 0.4, size = 0.8) +
  geom_vline(data = vlines, aes(xintercept = mean_val, color = group),
             linetype = "dashed", size = 0.7) +
  scale_fill_manual(values = c("Low Dep" = "blue", "High Dep" = "red")) +
  scale_color_manual(values = c("Low Dep" = "blue", "High Dep" = "red")) +
  facet_wrap(~ param_clean, scales = "free", ncol = 2) +
  theme_minimal(base_size = 14) +
  labs(title = paste("Posterior Distributions of Parameters by Dep Group (Cutoff:", sa_cutoff, ")"),
       x = "Parameter Value", y = "Density")






# Compute means per participant
w0_mean   <- apply(posterior$w0, 2, mean)
w1_mean   <- apply(posterior$w1, 2, mean)
w2_mean   <- apply(posterior$w2, 2, mean)
gam_mean  <- apply(posterior$gam, 2, mean)
sig_mean  <- apply(posterior$sig, 2, mean)

# Assuming SA scores are stored like this:
Dep_scores <- data %>%
  group_by(Random_ID) %>%
  summarise(Dep = first(Depression_score)) %>%
  arrange(Random_ID)

# Combine into a clean dataframe
param_df <- data.frame(
  ID = unique(data$Random_ID),
  Dep = Dep_scores$Dep,
  w0 = w0_mean,
  w1 = w1_mean,
  w2 = w2_mean,
  gamma = gam_mean,
  sigma = sig_mean
)

library(ggplot2)

# Function to create correlation plots
plot_correlation <- function(df, param, color = "#3366CC") {
  ggplot(df, aes_string(x = "Dep", y = param)) +
    geom_point(color = color, alpha = 0.7, size = 3) +
    geom_smooth(method = "lm", se = TRUE, color = "black", linetype = "dashed") +
    labs(
      x = "Depression Score",
      y = paste0("Mean Posterior of ", param),
      title = paste("Dep vs", param)
    ) +
    theme_minimal(base_size = 14)
}

# Plot examples
plot_correlation(param_df, "w0")
plot_correlation(param_df, "w1")
plot_correlation(param_df, "w2")
plot_correlation(param_df, "gamma")
plot_correlation(param_df, "sigma")

# Function to compute r and p for each parameter
get_corr_stats <- function(x, y) {
  test <- cor.test(x, y, method = "pearson")
  data.frame(
    r = round(test$estimate, 3),
    p_value = round(test$p.value, 4)
  )
}

# Apply to each parameter vs SA
corr_results <- rbind(
  get_corr_stats(param_df$Dep, param_df$w0),
  get_corr_stats(param_df$Dep, param_df$w1),
  get_corr_stats(param_df$Dep, param_df$w2),
  get_corr_stats(param_df$Dep, param_df$gamma),
  get_corr_stats(param_df$Dep, param_df$sigma)
)

# Label the rows
rownames(corr_results) <- c("w0", "w1", "w2", "gamma", "sigma")

# View results
print(corr_results)

```
