---
title: "Model_7_asymmetric_PE_simple_outcome_rstan"
format: html
editor: visual
---

## Asymmetric PEs and outcome model

In this model, anxiety/mood on trial $t$ is calculated by adding the intercept $\beta_0$ (the value of anxiety/mood when $W_{1t}$ and $W_{2t}$ are set to 0), a weighted cumulative PE, a weighted cumulative expectation on trial $t$ and a trait social anxiety score.

The term $\gamma^{(t - j)}$ decreases as $j$ becomes smaller relative to $t$. This means that PE and expectations closer to the current trial $t$ have larger weights, while PE and expectations further in the past have smaller weights. The exponential function ensures that PE and expectations further back in time are **"discounted" exponentially**. This is a type of **recency** **model**.

$$
A_t = \beta_0 +\beta_1\cdot  \sum_{j=1}^{t} \gamma^{t - j} \cdot PE_{pos}(j) + \beta_2\cdot \sum_{j=1}^{t} \gamma^{t - j} \cdot PE_{neg}(j)  + \beta_3\cdot O(t)\ + \beta_4\cdot SA 
$$

$$
M_t =\beta_0 +\beta_1\cdot  \sum_{j=1}^{t} \gamma^{t - j} \cdot PE_{pos}(j) + \beta_2\cdot \sum_{j=1}^{t} \gamma^{t - j} \cdot PE_{neg}(j)  + \beta_3\cdot O(t)\ + \beta_4\cdot SA 
$$

```{r}
########################################## For Anxiety ########################################
library(rstan)
library(dplyr)
library(ggplot2)

# Load Data
data <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/surprise_task_merged_data.csv")

# Ensure data is sorted by Random_ID and trial within each participant
data <- data[order(data$Random_ID), ]

# Extract unique participant IDs in order
participant_ids <- unique(data$Random_ID)
data$Response_SubjPE_scaled <- scale(data$Response_SubjPE)[, 1]
data$Response_fdbk <- scale(data$Response_fdbk)[, 1]
data$Response_Ax <- scale(data$Response_Ax)[, 1]
data$LSAS_Total <- scale(data$LSAS_Total)[, 1]

# Recalculate positive and negative PEs using original (unscaled) sign
data$Response_PosPE <- ifelse(data$Response_SubjPE > 0, data$Response_SubjPE_scaled, 0)
data$Response_NegPE <- ifelse(data$Response_SubjPE < 0, data$Response_SubjPE_scaled, 0)

# Recalculate LSAS vector in the correct order
Social_Anxiety_vector <- sapply(participant_ids, function(id) {
  unique(data$LSAS_Total[data$Random_ID == id])[1]
})

# Construct matrices in the same participant order
Response_fdbk_matrix <- matrix(data$Response_fdbk, nrow = N, ncol = T, byrow = TRUE)
Response_Ax_matrix <- matrix(data$Response_Ax, nrow = N, ncol = T, byrow = TRUE)
Response_PosPE_matrix <- matrix(data$Response_PosPE, nrow = N, ncol = T, byrow = TRUE)
Response_NegPE_matrix <- matrix(data$Response_NegPE, nrow = N, ncol = T, byrow = TRUE)



N <- length(unique(data$Random_ID))  # Number of participants
T <- 48  # Trials per participant

stan_data <- list(
  N = N,
  T = T,
  Tsubj = rep(48, N),
  Response_fdbk = Response_fdbk_matrix,
  Response_Ax = Response_Ax_matrix,
  Response_PosPE = Response_PosPE_matrix,
  Response_NegPE = Response_NegPE_matrix,
  Social_Anxiety = Social_Anxiety_vector

)




# Stan Model
asymmPE_simple_Outcome_anx_SA_LSAS <- "data {
  int<lower=1> N;
  int<lower=1> T;
  int<lower=1, upper=T> Tsubj[N]; 
  array[N, T] real Response_fdbk;
  array[N, T] real Response_Ax;
  array[N, T] real Response_PosPE;
  array[N, T] real Response_NegPE;
  vector[N] Social_Anxiety;
}
parameters {
  real intercept;
  real w1_mu;
  real w_pos_mu;
  real w_neg_mu;
  real gam_mu;
  real sig_mu;


  // Regression weights for Social_Anxiety
  real beta_w0;
  real beta_w1;
  real beta_w_pos;
  real beta_w_neg;
  real beta_gam;
  real beta_sig;
  real beta_SA;  // Direct effect of Social_Anxiety
  
  real<lower=0> sigma_w0;
  vector<lower=0>[5] sigma;

  vector[N] w0_pr;
  vector[N] w1_pr;
  vector[N] w_pos_pr;
  vector[N] w_neg_pr;
  vector[N] gam_pr;
  vector[N] sig_pr;
}
transformed parameters {
  vector[N] w0;
  vector[N] w1;
  vector[N] w_pos;
  vector[N] w_neg;
  vector<lower=0, upper=1>[N] gam;
  vector<lower=0>[N] sig;
  
  for (i in 1:N) {
    w0[i]  = intercept + beta_w0 * Social_Anxiety[i] + sigma_w0 * w0_pr[i];
    w1[i]  = w1_mu + beta_w1 * Social_Anxiety[i] + sigma[1] * w1_pr[i];
    w_pos[i]  = w_pos_mu + beta_w_pos * Social_Anxiety[i] + sigma[2] * w_pos_pr[i];
    w_neg[i]  = w_neg_mu + beta_w_neg * Social_Anxiety[i] + sigma[3] * w_neg_pr[i];

    gam[i] = Phi_approx(gam_mu + beta_gam * Social_Anxiety[i] + sigma[4] * gam_pr[i]);
    sig[i] = exp(sig_mu + beta_sig * Social_Anxiety[i] + sigma[5] * sig_pr[i]);
  }
}

model {
  intercept ~ normal(0, 1);
  w1_mu ~ normal(0, 0.5);
  w_pos_mu ~ normal(0, 0.5);
  w_neg_mu ~ normal(0, 0.5);
  gam_mu ~ normal(0, 0.5);
  sig_mu ~ normal(0, 0.5);

  beta_w0  ~ normal(0, 0.5);
  beta_w1  ~ normal(0, 0.5);
  beta_w_pos  ~ normal(0, 0.5);
  beta_w_neg  ~ normal(0, 0.5);
  beta_gam ~ normal(0, 0.5);
  beta_sig ~ normal(0, 0.5);
  beta_SA  ~ normal(0, 0.5);
  sigma_w0 ~ normal(0, 1);
  sigma ~ normal(0, 0.1);

  w0_pr ~ normal(0, 1);
  w1_pr ~ normal(0, 1);
  w_pos_pr ~ normal(0, 1);
  w_neg_pr ~ normal(0, 1);
  gam_pr ~ normal(0, 1);
  sig_pr ~ normal(0, 1);

  for (i in 1:N) {
    real pospe_sum = 0;
    real negpe_sum = 0;

    for (t in 1:Tsubj[i]) {
      Response_Ax[i, t] ~ normal(
        w0[i] + w1[i] * Response_fdbk[i, t] + w_pos[i] * pospe_sum + w_neg[i] * negpe_sum + beta_SA * Social_Anxiety[i],sig[i]);

      pospe_sum += Response_PosPE[i, t];
      negpe_sum += Response_NegPE[i, t];

      pospe_sum *= gam[i];
      negpe_sum *= gam[i];
    }
  }
}
generated quantities {
  real mu_w0;
  real mu_w1;
  real mu_w_pos;
  real mu_w_neg;
  real<lower=0, upper=1> mu_gam;
  real<lower=0> mu_sig;

  real log_lik[N];
  real y_pred[N, T];

  mu_w0 = intercept;
  mu_w1 = w1_mu;
  mu_w_pos = w_pos_mu;
  mu_w_neg = w_neg_mu;
  mu_gam = Phi_approx(gam_mu);
  mu_sig = exp(sig_mu);

  for (i in 1:N) {
    real pospe_sum = 0;
    real negpe_sum = 0;
    log_lik[i] = 0;

    for (t in 1:Tsubj[i]) {
      real mu = w0[i] + w1[i] * Response_fdbk[i, t] + w_pos[i] * pospe_sum + w_neg[i] * negpe_sum + beta_SA * Social_Anxiety[i];
      log_lik[i] += normal_lpdf(Response_Ax[i, t] | mu, sig[i]);
      y_pred[i, t] = normal_rng(mu, sig[i]);

      pospe_sum += Response_PosPE[i, t];
      negpe_sum += Response_NegPE[i, t];

      pospe_sum *= gam[i];
      negpe_sum *= gam[i];
    }
  }
}
"

```

```{r}

# Compile and Fit the Model
asymmPE_simple_Outcome_anx_SA_LSAS_fit <- stan(model_code = asymmPE_simple_Outcome_anx_SA_LSAS, data = stan_data, iter = 4000, warmup = 2000, chains = 4, seed = 123, cores = 4, control = list(adapt_delta = 0.95,
  max_treedepth = 10))

options(max.print = 9999)  

# Print results
print(asymmPE_simple_Outcome_anx_SA_LSAS_fit)


saveRDS(asymmPE_simple_Outcome_anx_SA_LSAS_fit, "asymmPE_simple_Outcome_anx_SA_LSAS_fit.rds")
```

```{r}

asymmPE_simple_Outcome_anx_SA_LSAS_fit <- readRDS("asymmPE_simple_Outcome_anx_SA_LSAS_fit.rds")

# Plot results
traceplot(asymmPE_simple_Outcome_anx_SA_LSAS_fit)

# Extract posterior samples
posterior_samples <- rstan::extract(asymmPE_simple_Outcome_anx_SA_LSAS_fit)

library(ggplot2)
library(dplyr)
library(tidyr)


# 2. Calculate the estimated Response_Ax for each participant
# Generate the estimated Response_Ax from posterior predictive distribution
y_pred <- posterior_samples$y_pred


# Extract log-likelihood per participant (N-length vector)
log_lik_vector <- rstan::extract(asymmPE_simple_Outcome_anx_SA_LSAS_fit, pars = "log_lik")$log_lik  # Dimensions: [S, N] (S = posterior samples)

# Compute LOO-CV
library(loo)
loo_result <- loo(log_lik_vector)
print(loo_result)
dim(log_lik_vector)
library(loo)

# Compute WAIC
waic_result <- waic(log_lik_vector)
print(waic_result)



# Extract the posterior samples
posterior_samples <- rstan::extract(asymmPE_simple_Outcome_anx_SA_LSAS_fit)

# Predicted values (posterior predictive distribution)
y_pred <- posterior_samples$y_pred
# Load required package
library(matrixStats)

# Compute mean predicted values (posterior mean)
y_pred_mean <- apply(y_pred, c(2,3), mean)  # Mean across posterior samples

# Compute MSE
mse <- mean((y_pred_mean - stan_data$Response_Ax)^2)

# Compute MAE
mae <- mean(abs(y_pred_mean -  stan_data$Response_Ax))

print(paste("MSE:", mse))
print(paste("MAE:", mae))


y_pred_mean <- apply(posterior_samples$y_pred, c(2, 3), mean) 
y_pred_df <- as.data.frame(y_pred_mean)
colnames(y_pred_df) <- paste0("Trial_", 1:T)
y_pred_df$Random_ID <- unique(data$Random_ID)


# Convert Response_Ax to matrix and then to a data frame
Response_Ax_matrix <- matrix(data$Response_Ax, nrow = N, ncol = T, byrow = TRUE)
Response_Ax_df <- as.data.frame(Response_Ax_matrix)
colnames(Response_Ax_df) <- paste0("Trial_", 1:T)
Response_Ax_df$Random_ID <- unique(data$Random_ID)

# Reshape data into long format
y_pred_long <- pivot_longer(y_pred_df, cols = starts_with("Trial_"), names_to = "Trial", values_to = "Predicted_Response")
Response_Ax_long <- pivot_longer(Response_Ax_df, cols = starts_with("Trial_"), names_to = "Trial", values_to = "Actual_Response")

# Merge actual and predicted data
plot_data <- left_join(Response_Ax_long, y_pred_long, by = c("Random_ID", "Trial"))

# Convert Trial to numeric
plot_data$Trial <- as.numeric(gsub("Trial_", "", plot_data$Trial))



# Plot individual real data and fitted curve for each participant using ggplot2
ggplot(plot_data, aes(x = Trial)) +
  geom_line(aes(y = Actual_Response), color = "blue", size = 1) + 
  geom_line(aes(y = Predicted_Response), color = "red", size = 1) +
  facet_wrap(~ Random_ID, scales = "free_y") +
  labs(title = "Real Data and Fitted Curve per Participant",
       x = "Trial Number",
       y = "Anxiety") +
  ylim(-3,3)
  theme_minimal()

  
library(bayesplot)
y_obs <- stan_data$Response_Ax
# Select a subset of posterior draws for plotting
set.seed(123)
draws_to_plot <- sample(1:dim(y_pred)[1], 20)  # e.g. 20 random posterior draws
y_pred_subset <- y_pred[draws_to_plot,,]        # Subset of y_rep

# Flatten y_obs for histogram comparison
y_obs_flat <- as.vector(y_obs)

# Convert y_rep_subset into a matrix: draws x (N*T)
y_pred_matrix <- apply(y_pred_subset, 1, function(mat) as.vector(t(mat)))
y_pred_matrix <- t(y_pred_matrix)  # make it draws x obs

# Now plot
color_scheme_set("blue")
ppc_hist(y_obs_flat, y_pred_matrix[1:8, ])  # show 8 histograms for example

```

```{r}

posterior <- rstan::extract(asymmPE_simple_Outcome_anx_SA_LSAS_fit)

# Define binary groups based on threshold
sa_cutoff <- -0.90
SA_vals <- stan_data$Social_Anxiety  # Vector of length N
group_labels <- ifelse(SA_vals >= sa_cutoff, "High SA", "Low SA")

# Separate SA values by group
low_SA_vals  <- SA_vals[SA_vals < sa_cutoff]
high_SA_vals <- SA_vals[SA_vals >= sa_cutoff]

# Number of posterior samples
n_samples <- length(posterior$intercept)

# For each group, calculate the parameter across participants and average
w0_low  <- rowMeans(matrix(posterior$intercept, nrow = n_samples, ncol = length(low_SA_vals)) +
                    posterior$beta_w0 %o% low_SA_vals)

w0_high <- rowMeans(matrix(posterior$intercept, nrow = n_samples, ncol = length(high_SA_vals)) +
                    posterior$beta_w0 %o% high_SA_vals)

# Same for w1
w1_low  <- rowMeans(matrix(posterior$w1_mu, nrow = n_samples, ncol = length(low_SA_vals)) +
                    posterior$beta_w1 %o% low_SA_vals)

w1_high <- rowMeans(matrix(posterior$w1_mu, nrow = n_samples, ncol = length(high_SA_vals)) +
                    posterior$beta_w1 %o% high_SA_vals)

w_pos_low  <- rowMeans(matrix(posterior$w_pos_mu, nrow = n_samples, ncol = length(low_SA_vals)) +
                    posterior$beta_w_pos %o% low_SA_vals)

w_pos_high <- rowMeans(matrix(posterior$w_pos_mu, nrow = n_samples, ncol = length(high_SA_vals)) +
                    posterior$beta_w_pos %o% high_SA_vals)


w_neg_low  <- rowMeans(matrix(posterior$w_neg_mu, nrow = n_samples, ncol = length(low_SA_vals)) +
                    posterior$beta_w_neg %o% low_SA_vals)

w_neg_high <- rowMeans(matrix(posterior$w_neg_mu, nrow = n_samples, ncol = length(high_SA_vals)) +
                    posterior$beta_w_neg %o% high_SA_vals)

# Gamma (use pnorm)
gamma_low  <- rowMeans(pnorm(matrix(posterior$gam_mu, nrow = n_samples, ncol = length(low_SA_vals)) +
                             posterior$beta_gam %o% low_SA_vals))

gamma_high <- rowMeans(pnorm(matrix(posterior$gam_mu, nrow = n_samples, ncol = length(high_SA_vals)) +
                             posterior$beta_gam %o% high_SA_vals))

# Sigma (use exp)
sigma_low  <- rowMeans(exp(matrix(posterior$sig_mu, nrow = n_samples, ncol = length(low_SA_vals)) +
                           posterior$beta_sig %o% low_SA_vals))

sigma_high <- rowMeans(exp(matrix(posterior$sig_mu, nrow = n_samples, ncol = length(high_SA_vals)) +
                           posterior$beta_sig %o% high_SA_vals))


# Helper function for mean and 95% CI
summarize_param <- function(low, high) {
  low_mean  <- mean(low)
  high_mean <- mean(high)
  diff <- high - low
  diff_mean <- mean(diff)
  
  low_CI  <- quantile(low, probs = c(0.025, 0.975))
  high_CI <- quantile(high, probs = c(0.025, 0.975))
  diff_CI <- quantile(diff, probs = c(0.025, 0.975))
  
  data.frame(
    `Low SA Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", low_mean,  low_CI[1],  low_CI[2]),
    `High SA Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", high_mean, high_CI[1], high_CI[2]),
    `High - Low Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", diff_mean, diff_CI[1], diff_CI[2])
  )
}

# Generate summary table
summary_table <- rbind(
  summarize_param(w0_low, w0_high),
  summarize_param(w1_low, w1_high),
  summarize_param(w_pos_low, w_pos_high),
  summarize_param(w_neg_low, w_neg_high),
  summarize_param(gamma_low, gamma_high),
  summarize_param(sigma_low, sigma_high)
)

summary_table <- cbind(Parameter = c("w0", "w1", "w_pos", "w_neg", "gamma", "sigma"), summary_table)

# Show table
print(summary_table, row.names = FALSE)

# Prepare for plotting
posterior_df <- data.frame(
  w0_low, w0_high,
  w1_low, w1_high,
  w_pos_low, w_pos_high,
  w_neg_low, w_neg_high,
  gamma_low, gamma_high,
  sigma_low, sigma_high
)

plot_data <- posterior_df %>%
  pivot_longer(cols = everything(), names_to = "param", values_to = "value") %>%
  mutate(
    group = ifelse(grepl("_low", param), "Low SA", "High SA"),
    param_clean = gsub("_(low|high)", "", param)
  )

# Calculate group means for vertical lines
vlines <- plot_data %>%
  group_by(param_clean, group) %>%
  summarise(mean_val = mean(value), .groups = "drop")

# Plot posterior densities with vertical lines
ggplot(plot_data, aes(x = value, fill = group, color = group)) +
  geom_density(alpha = 0.4, size = 0.8) +
  geom_vline(data = vlines, aes(xintercept = mean_val, color = group),
             linetype = "dashed", size = 0.7) +
  scale_fill_manual(values = c("Low SA" = "blue", "High SA" = "red")) +
  scale_color_manual(values = c("Low SA" = "blue", "High SA" = "red")) +
  facet_wrap(~ param_clean, scales = "free", ncol = 2) +
  theme_minimal(base_size = 14) +
  labs(title = paste("Posterior Distributions of Parameters by SA Group (Cutoff:", sa_cutoff, ")"),
       x = "Parameter Value", y = "Density")






# Compute means per participant
w0_mean   <- apply(posterior$w0, 2, mean)
w1_mean   <- apply(posterior$w1, 2, mean)
w_pos_mean   <- apply(posterior$w_pos, 2, mean)
w_neg_mean   <- apply(posterior$w_neg, 2, mean)
gam_mean  <- apply(posterior$gam, 2, mean)
sig_mean  <- apply(posterior$sig, 2, mean)

# Assuming SA scores are stored like this:
SA_scores <- data %>%
  group_by(Random_ID) %>%
  summarise(SA = first(LSAS_Total)) %>%
  arrange(Random_ID)

# Combine into a clean dataframe
param_df <- data.frame(
  ID = unique(data$Random_ID),
  SA = SA_scores$SA,
  w0 = w0_mean,
  w1 = w1_mean,
  w_pos = w_pos_mean,
  w_neg = w_neg_mean,
  gamma = gam_mean,
  sigma = sig_mean
)

library(ggplot2)

# Function to create correlation plots
plot_correlation <- function(df, param, color = "#3366CC") {
  ggplot(df, aes_string(x = "SA", y = param)) +
    geom_point(color = color, alpha = 0.7, size = 3) +
    geom_smooth(method = "lm", se = TRUE, color = "black", linetype = "dashed") +
    labs(
      x = "Social Anxiety Score",
      y = paste0("Mean Posterior of ", param),
      title = paste("SA vs", param)
    ) +
    theme_minimal(base_size = 14)
}

# Plot examples
plot_correlation(param_df, "w0")
plot_correlation(param_df, "w1")
plot_correlation(param_df, "w_pos")
plot_correlation(param_df, "w_neg")
plot_correlation(param_df, "gamma")
plot_correlation(param_df, "sigma")

# Function to compute r and p for each parameter
get_corr_stats <- function(x, y) {
  test <- cor.test(x, y, method = "pearson")
  data.frame(
    r = round(test$estimate, 3),
    p_value = round(test$p.value, 4)
  )
}

# Apply to each parameter vs SA
corr_results <- rbind(
  get_corr_stats(param_df$SA, param_df$w0),
  get_corr_stats(param_df$SA, param_df$w1),
  get_corr_stats(param_df$SA, param_df$w_pos),
    get_corr_stats(param_df$SA, param_df$w_neg),
  get_corr_stats(param_df$SA, param_df$gamma),
  get_corr_stats(param_df$SA, param_df$sigma)
)

# Label the rows
rownames(corr_results) <- c("w0", "w1", "w_pos", "w_neg", "gamma", "sigma")

# View results
print(corr_results)


```

```{r}
rm(list = ls())
########################################## For Mood ########################################
library(rstan)
library(dplyr)
library(ggplot2)


# Load Data
data <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/surprise_task_merged_data.csv")

# Ensure data is sorted by Random_ID and trial within each participant
data <- data[order(data$Random_ID), ]

# Extract unique participant IDs in order
participant_ids <- unique(data$Random_ID)
data$Response_SubjPE_scaled <- scale(data$Response_SubjPE)[, 1]
data$Response_fdbk <- scale(data$Response_fdbk)[, 1]
data$Response_H <- scale(data$Response_H)[, 1]
data$LSAS_Total <- scale(data$LSAS_Total)[, 1]

# Recalculate positive and negative PEs using original (unscaled) sign
data$Response_PosPE <- ifelse(data$Response_SubjPE > 0, data$Response_SubjPE_scaled, 0)
data$Response_NegPE <- ifelse(data$Response_SubjPE < 0, data$Response_SubjPE_scaled, 0)

# Recalculate LSAS vector in the correct order
Social_Anxiety_vector <- sapply(participant_ids, function(id) {
  unique(data$LSAS_Total[data$Random_ID == id])[1]
})

# Construct matrices in the same participant order
Response_fdbk_matrix <- matrix(data$Response_fdbk, nrow = N, ncol = T, byrow = TRUE)
Response_H_matrix <- matrix(data$Response_H, nrow = N, ncol = T, byrow = TRUE)
Response_PosPE_matrix <- matrix(data$Response_PosPE, nrow = N, ncol = T, byrow = TRUE)
Response_NegPE_matrix <- matrix(data$Response_NegPE, nrow = N, ncol = T, byrow = TRUE)



N <- length(unique(data$Random_ID))  # Number of participants
T <- 48  # Trials per participant

stan_data <- list(
  N = N,
  T = T,
  Tsubj = rep(48, N),
  Response_fdbk = Response_fdbk_matrix,
  Response_H = Response_H_matrix,
  Response_PosPE = Response_PosPE_matrix,
  Response_NegPE = Response_NegPE_matrix,
  Social_Anxiety = Social_Anxiety_vector

)




# Stan Model
asymmPE_simple_Outcome_mood_SA_LSAS <- "data {
  int<lower=1> N;
  int<lower=1> T;
  int<lower=1, upper=T> Tsubj[N]; 
  array[N, T] real Response_fdbk;
  array[N, T] real Response_H;
  array[N, T] real Response_PosPE;
  array[N, T] real Response_NegPE;
  vector[N] Social_Anxiety;
}
parameters {
  real intercept;
  real w1_mu;
  real w_pos_mu;
  real w_neg_mu;
  real gam_mu;
  real sig_mu;


  // Regression weights for Social_Anxiety
  real beta_w0;
  real beta_w1;
  real beta_w_pos;
  real beta_w_neg;
  real beta_gam;
  real beta_sig;
  real beta_SA;  // Direct effect of Social_Anxiety
  
  real<lower=0> sigma_w0;
  vector<lower=0>[5] sigma;

  vector[N] w0_pr;
  vector[N] w1_pr;
  vector[N] w_pos_pr;
  vector[N] w_neg_pr;
  vector[N] gam_pr;
  vector[N] sig_pr;
}
transformed parameters {
  vector[N] w0;
  vector[N] w1;
  vector[N] w_pos;
  vector[N] w_neg;
  vector<lower=0, upper=1>[N] gam;
  vector<lower=0>[N] sig;
  
  for (i in 1:N) {
    w0[i]  = intercept + beta_w0 * Social_Anxiety[i] + sigma_w0 * w0_pr[i];
    w1[i]  = w1_mu + beta_w1 * Social_Anxiety[i] + sigma[1] * w1_pr[i];
    w_pos[i]  = w_pos_mu + beta_w_pos * Social_Anxiety[i] + sigma[2] * w_pos_pr[i];
    w_neg[i]  = w_neg_mu + beta_w_neg * Social_Anxiety[i] + sigma[3] * w_neg_pr[i];

    gam[i] = Phi_approx(gam_mu + beta_gam * Social_Anxiety[i] + sigma[4] * gam_pr[i]);
    sig[i] = exp(sig_mu + beta_sig * Social_Anxiety[i] + sigma[5] * sig_pr[i]);
  }
}

model {
  intercept ~ normal(0, 1);
  w1_mu ~ normal(0, 0.5);
  w_pos_mu ~ normal(0, 0.5);
  w_neg_mu ~ normal(0, 0.5);
  gam_mu ~ normal(0, 0.5);
  sig_mu ~ normal(0, 0.5);

  beta_w0  ~ normal(0, 0.5);
  beta_w1  ~ normal(0, 0.5);
  beta_w_pos  ~ normal(0, 0.5);
  beta_w_neg  ~ normal(0, 0.5);
  beta_gam ~ normal(0, 0.5);
  beta_sig ~ normal(0, 0.5);
  beta_SA  ~ normal(0, 0.5);
  sigma_w0 ~ normal(0, 1);
  sigma ~ normal(0, 0.1);

  w0_pr ~ normal(0, 1);
  w1_pr ~ normal(0, 1);
  w_pos_pr ~ normal(0, 1);
  w_neg_pr ~ normal(0, 1);
  gam_pr ~ normal(0, 1);
  sig_pr ~ normal(0, 1);

  for (i in 1:N) {
    real pospe_sum = 0;
    real negpe_sum = 0;

    for (t in 1:Tsubj[i]) {
      Response_H[i, t] ~ normal(
        w0[i] + w1[i] * Response_fdbk[i, t] + w_pos[i] * pospe_sum + w_neg[i] * negpe_sum + beta_SA * Social_Anxiety[i],sig[i]);

      pospe_sum += Response_PosPE[i, t];
      negpe_sum += Response_NegPE[i, t];

      pospe_sum *= gam[i];
      negpe_sum *= gam[i];
    }
  }
}
generated quantities {
  real mu_w0;
  real mu_w1;
  real mu_w_pos;
  real mu_w_neg;
  real<lower=0, upper=1> mu_gam;
  real<lower=0> mu_sig;

  real log_lik[N];
  real y_pred[N, T];

  mu_w0 = intercept;
  mu_w1 = w1_mu;
  mu_w_pos = w_pos_mu;
  mu_w_neg = w_neg_mu;
  mu_gam = Phi_approx(gam_mu);
  mu_sig = exp(sig_mu);

  for (i in 1:N) {
    real pospe_sum = 0;
    real negpe_sum = 0;
    log_lik[i] = 0;

    for (t in 1:Tsubj[i]) {
      real mu = w0[i] + w1[i] * Response_fdbk[i, t] + w_pos[i] * pospe_sum + w_neg[i] * negpe_sum + beta_SA * Social_Anxiety[i];
      log_lik[i] += normal_lpdf(Response_H[i, t] | mu, sig[i]);
      y_pred[i, t] = normal_rng(mu, sig[i]);

      pospe_sum += Response_PosPE[i, t];
      negpe_sum += Response_NegPE[i, t];

      pospe_sum *= gam[i];
      negpe_sum *= gam[i];
    }
  }
}
"

```

```{r}

# Compile and Fit the Model
asymmPE_simple_Outcome_mood_SA_LSAS_fit <- stan(model_code = asymmPE_simple_Outcome_mood_SA_LSAS, data = stan_data, iter = 4000, warmup = 2000, chains = 4, seed = 123, cores = 4, control = list(adapt_delta = 0.95,
  max_treedepth = 10))

options(max.print = 9999)  # Set a higher limit

# Print results
print(asymmPE_simple_Outcome_mood_SA_LSAS_fit)

saveRDS(asymmPE_simple_Outcome_mood_SA_LSAS_fit, "asymmPE_simple_Outcome_mood_SA_LSAS_fit.rds")
```

```{r}
# Plot results
traceplot(asymmPE_simple_Outcome_mood_SA_LSAS_fit)

# Extract posterior samples
posterior_samples <- rstan::extract(asymmPE_simple_Outcome_mood_SA_LSAS_fit)

library(ggplot2)
library(dplyr)
library(tidyr)


# 2. Calculate the estimated Response_H for each participant
# Generate the estimated Response_H from posterior predictive distribution
y_pred <- posterior_samples$y_pred


# Extract log-likelihood per participant (N-length vector)
log_lik_vector <- rstan::extract(asymmPE_simple_Outcome_mood_SA_LSAS_fit, pars = "log_lik")$log_lik  # Dimensions: [S, N] (S = posterior samples)

# Compute LOO-CV
library(loo)
loo_result <- loo(log_lik_vector)
print(loo_result)
dim(log_lik_vector)
library(loo)

# Compute WAIC
waic_result <- waic(log_lik_vector)
print(waic_result)



# Extract the posterior samples
posterior_samples <- rstan::extract(asymmPE_simple_Outcome_mood_SA_LSAS_fit)

# Predicted values (posterior predictive distribution)
y_pred <- posterior_samples$y_pred
# Load required package
library(matrixStats)

# Compute mean predicted values (posterior mean)
y_pred_mean <- apply(y_pred, c(2,3), mean)  # Mean across posterior samples

# Compute MSE
mse <- mean((y_pred_mean - stan_data$Response_H)^2)

# Compute MAE
mae <- mean(abs(y_pred_mean -  stan_data$Response_H))

print(paste("MSE:", mse))
print(paste("MAE:", mae))


y_pred_mean <- apply(posterior_samples$y_pred, c(2, 3), mean) 
y_pred_df <- as.data.frame(y_pred_mean)
colnames(y_pred_df) <- paste0("Trial_", 1:T)
y_pred_df$Random_ID <- unique(data$Random_ID)


# Convert Response_Ax to matrix and then to a data frame
Response_H_matrix <- matrix(data$Response_H, nrow = N, ncol = T, byrow = TRUE)
Response_H_df <- as.data.frame(Response_H_matrix)
colnames(Response_H_df) <- paste0("Trial_", 1:T)
Response_H_df$Random_ID <- unique(data$Random_ID)

# Reshape data into long format
y_pred_long <- pivot_longer(y_pred_df, cols = starts_with("Trial_"), names_to = "Trial", values_to = "Predicted_Response")
Response_H_long <- pivot_longer(Response_H_df, cols = starts_with("Trial_"), names_to = "Trial", values_to = "Actual_Response")

# Merge actual and predicted data
plot_data <- left_join(Response_H_long, y_pred_long, by = c("Random_ID", "Trial"))

# Convert Trial to numeric
plot_data$Trial <- as.numeric(gsub("Trial_", "", plot_data$Trial))



# Plot individual real data and fitted curve for each participant using ggplot2
ggplot(plot_data, aes(x = Trial)) +
  geom_line(aes(y = Actual_Response), color = "blue", size = 1) + 
  geom_line(aes(y = Predicted_Response), color = "red", size = 1) +
  facet_wrap(~ Random_ID, scales = "free_y") +
  labs(title = "Real Data and Fitted Curve per Participant",
       x = "Trial Number",
       y = "Mood") +
  ylim(-3,3)
  theme_minimal()

  
library(bayesplot)
y_obs <- stan_data$Response_H
# Select a subset of posterior draws for plotting
set.seed(123)
draws_to_plot <- sample(1:dim(y_pred)[1], 20)  # e.g. 20 random posterior draws
y_pred_subset <- y_pred[draws_to_plot,,]        # Subset of y_rep

# Flatten y_obs for histogram comparison
y_obs_flat <- as.vector(y_obs)

# Convert y_rep_subset into a matrix: draws x (N*T)
y_pred_matrix <- apply(y_pred_subset, 1, function(mat) as.vector(t(mat)))
y_pred_matrix <- t(y_pred_matrix)  # make it draws x obs

# Now plot
color_scheme_set("blue")
ppc_hist(y_obs_flat, y_pred_matrix[1:8, ])  # show 8 histograms for example

```

```{r}
posterior <- rstan::extract(asymmPE_simple_Outcome_mood_SA_LSAS_fit)

# Define binary groups based on threshold
sa_cutoff <- -0.9
SA_vals <- stan_data$Social_Anxiety  # Vector of length N
group_labels <- ifelse(SA_vals >= sa_cutoff, "High SA", "Low SA")

# Separate SA values by group
low_SA_vals  <- SA_vals[SA_vals < sa_cutoff]
high_SA_vals <- SA_vals[SA_vals >= sa_cutoff]

# Number of posterior samples
n_samples <- length(posterior$intercept)

# For each group, calculate the parameter across participants and average
w0_low  <- rowMeans(matrix(posterior$intercept, nrow = n_samples, ncol = length(low_SA_vals)) +
                    posterior$beta_w0 %o% low_SA_vals)

w0_high <- rowMeans(matrix(posterior$intercept, nrow = n_samples, ncol = length(high_SA_vals)) +
                    posterior$beta_w0 %o% high_SA_vals)

# Same for w1
w1_low  <- rowMeans(matrix(posterior$w1_mu, nrow = n_samples, ncol = length(low_SA_vals)) +
                    posterior$beta_w1 %o% low_SA_vals)

w1_high <- rowMeans(matrix(posterior$w1_mu, nrow = n_samples, ncol = length(high_SA_vals)) +
                    posterior$beta_w1 %o% high_SA_vals)

w_pos_low  <- rowMeans(matrix(posterior$w_pos_mu, nrow = n_samples, ncol = length(low_SA_vals)) +
                    posterior$beta_w_pos %o% low_SA_vals)

w_pos_high <- rowMeans(matrix(posterior$w_pos_mu, nrow = n_samples, ncol = length(high_SA_vals)) +
                    posterior$beta_w_pos %o% high_SA_vals)


w_neg_low  <- rowMeans(matrix(posterior$w_neg_mu, nrow = n_samples, ncol = length(low_SA_vals)) +
                    posterior$beta_w_neg %o% low_SA_vals)

w_neg_high <- rowMeans(matrix(posterior$w_neg_mu, nrow = n_samples, ncol = length(high_SA_vals)) +
                    posterior$beta_w_neg %o% high_SA_vals)

# Gamma (use pnorm)
gamma_low  <- rowMeans(pnorm(matrix(posterior$gam_mu, nrow = n_samples, ncol = length(low_SA_vals)) +
                             posterior$beta_gam %o% low_SA_vals))

gamma_high <- rowMeans(pnorm(matrix(posterior$gam_mu, nrow = n_samples, ncol = length(high_SA_vals)) +
                             posterior$beta_gam %o% high_SA_vals))

# Sigma (use exp)
sigma_low  <- rowMeans(exp(matrix(posterior$sig_mu, nrow = n_samples, ncol = length(low_SA_vals)) +
                           posterior$beta_sig %o% low_SA_vals))

sigma_high <- rowMeans(exp(matrix(posterior$sig_mu, nrow = n_samples, ncol = length(high_SA_vals)) +
                           posterior$beta_sig %o% high_SA_vals))


# Helper function for mean and 95% CI
summarize_param <- function(low, high) {
  low_mean  <- mean(low)
  high_mean <- mean(high)
  diff <- high - low
  diff_mean <- mean(diff)
  
  low_CI  <- quantile(low, probs = c(0.025, 0.975))
  high_CI <- quantile(high, probs = c(0.025, 0.975))
  diff_CI <- quantile(diff, probs = c(0.025, 0.975))
  
  data.frame(
    `Low SA Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", low_mean,  low_CI[1],  low_CI[2]),
    `High SA Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", high_mean, high_CI[1], high_CI[2]),
    `High - Low Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", diff_mean, diff_CI[1], diff_CI[2])
  )
}

# Generate summary table
summary_table <- rbind(
  summarize_param(w0_low, w0_high),
  summarize_param(w1_low, w1_high),
  summarize_param(w_pos_low, w_pos_high),
  summarize_param(w_neg_low, w_neg_high),
  summarize_param(gamma_low, gamma_high),
  summarize_param(sigma_low, sigma_high)
)

summary_table <- cbind(Parameter = c("w0", "w1", "w_pos", "w_neg", "gamma", "sigma"), summary_table)

# Show table
print(summary_table, row.names = FALSE)

# Prepare for plotting
posterior_df <- data.frame(
  w0_low, w0_high,
  w1_low, w1_high,
  w_pos_low, w_pos_high,
  w_neg_low, w_neg_high,
  gamma_low, gamma_high,
  sigma_low, sigma_high
)

plot_data <- posterior_df %>%
  pivot_longer(cols = everything(), names_to = "param", values_to = "value") %>%
  mutate(
    group = ifelse(grepl("_low", param), "Low SA", "High SA"),
    param_clean = gsub("_(low|high)", "", param)
  )

# Calculate group means for vertical lines
vlines <- plot_data %>%
  group_by(param_clean, group) %>%
  summarise(mean_val = mean(value), .groups = "drop")

# Plot posterior densities with vertical lines
ggplot(plot_data, aes(x = value, fill = group, color = group)) +
  geom_density(alpha = 0.4, size = 0.8) +
  geom_vline(data = vlines, aes(xintercept = mean_val, color = group),
             linetype = "dashed", size = 0.7) +
  scale_fill_manual(values = c("Low SA" = "blue", "High SA" = "red")) +
  scale_color_manual(values = c("Low SA" = "blue", "High SA" = "red")) +
  facet_wrap(~ param_clean, scales = "free", ncol = 2) +
  theme_minimal(base_size = 14) +
  labs(title = paste("Posterior Distributions of Parameters by SA Group (Cutoff:", sa_cutoff, ")"),
       x = "Parameter Value", y = "Density")






# Compute means per participant
w0_mean   <- apply(posterior$w0, 2, mean)
w1_mean   <- apply(posterior$w1, 2, mean)
w_pos_mean   <- apply(posterior$w_pos, 2, mean)
w_neg_mean   <- apply(posterior$w_neg, 2, mean)
gam_mean  <- apply(posterior$gam, 2, mean)
sig_mean  <- apply(posterior$sig, 2, mean)

# Assuming SA scores are stored like this:
SA_scores <- data %>%
  group_by(Random_ID) %>%
  summarise(SA = first(LSAS_Total)) %>%
  arrange(Random_ID)

# Combine into a clean dataframe
param_df <- data.frame(
  ID = unique(data$Random_ID),
  SA = SA_scores$SA,
  w0 = w0_mean,
  w1 = w1_mean,
  w_pos = w_pos_mean,
  w_neg = w_neg_mean,
  gamma = gam_mean,
  sigma = sig_mean
)

library(ggplot2)

# Function to create correlation plots
plot_correlation <- function(df, param, color = "#3366CC") {
  ggplot(df, aes_string(x = "SA", y = param)) +
    geom_point(color = color, alpha = 0.7, size = 3) +
    geom_smooth(method = "lm", se = TRUE, color = "black", linetype = "dashed") +
    labs(
      x = "Social Anxiety Score",
      y = paste0("Mean Posterior of ", param),
      title = paste("SA vs", param)
    ) +
    theme_minimal(base_size = 14)
}

# Plot examples
plot_correlation(param_df, "w0")
plot_correlation(param_df, "w1")
plot_correlation(param_df, "w_pos")
plot_correlation(param_df, "w_neg")
plot_correlation(param_df, "gamma")
plot_correlation(param_df, "sigma")

# Function to compute r and p for each parameter
get_corr_stats <- function(x, y) {
  test <- cor.test(x, y, method = "pearson")
  data.frame(
    r = round(test$estimate, 3),
    p_value = round(test$p.value, 4)
  )
}

# Apply to each parameter vs SA
corr_results <- rbind(
  get_corr_stats(param_df$SA, param_df$w0),
  get_corr_stats(param_df$SA, param_df$w1),
  get_corr_stats(param_df$SA, param_df$w_pos),
    get_corr_stats(param_df$SA, param_df$w_neg),
  get_corr_stats(param_df$SA, param_df$gamma),
  get_corr_stats(param_df$SA, param_df$sigma)
)

# Label the rows
rownames(corr_results) <- c("w0", "w1", "w_pos", "w_neg", "gamma", "sigma")

# View results
print(corr_results)


```

```{r}


```
