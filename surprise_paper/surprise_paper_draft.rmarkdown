---
title: "Social Surprises and Social Feedback Shape Momentary Mood in Humans"
author:
  - name: Elena Bagdades
    orcid: 0009-0002-1971-5607
    affiliations: 
    - ref: 1
    - ref: 2
  - name: Marjan Biria
    orcid: 0000-0003-2671-0150
    affiliations: 
    - ref: 1
    - ref: 6
  - name: Charlotte Burman
    orcid: 
    affiliations: 
    - ref: 2
  - name: Jessica Norman
    orcid: 
    affiliations: 
    - ref: 1
    - ref: 2
  - name: Raphaelle Delpech
    orcid: 0000-0003-3098-5077
    affiliations: 
    - ref: 2
  - name: Madeleine Moses-Payne
    orcid: 0000-0001-7837-1096
    affiliations: 
    - ref: 2
  - name: Naomi Tromans
    orcid: 
    affiliations: 
    - ref: 2
    - ref: 3
  - name: Lucienne Spencer
    orcid: 0000-0002-4929-5300
    affiliations:
    - ref: 3
  - name: Ilina Singh
    orcid: 0000-0003-4497-3587
    affiliations:
    - ref: 3
  - name: Eleanor Leigh
    orcid: 0000-0003-2756-3770
    affiliations:
    - ref: 3
    - ref: 5
  - name: Georgina Krebs
    orcid: 0000-0002-5353-5645
    affiliation:
    - ref: 1
  - name: Argyris Stringaris
    orcid: 0000-0002-6264-8377
    affiliations:
    - ref: 1
    - ref: 2
    - ref: 4
date: '`r paste("Date:", format(Sys.Date(), "%d.%m.%Y"))`'
format: docx
bibliography: "Surprise paper.bib"
csl: apa.csl
tbl-cap-location: top
fig-cap-location: bottom
fig-dpi: 300
affiliations:
  - id: 1
    name: Department of Clinical, Educational & Health Psychology, Division of Psychology and Language Sciences, University College London
  - id: 2
    name: Department of Mental Health Neuroscience, Division of Psychiatry, University College London
  - id: 3
    name: Department of Experimental Psychology, University of Oxford, Oxford, UK
  - id: 4
    name: Department of Psychiatry, National and Kapodistrian University of Athens, Greece
  - id: 5
    name: Oxford Health NHS Foundation Trust, Oxford, UK
  - id: 6
    name: Department of Psychology, Institute of Psychiatry, Psychology & Neuroscience, King's College London, UK
---

```{r load-packages}
#| include: false
library("knitr")
library("flextable")
library("tidyverse")
library("HDInterval")
library("cowplot")
library("patchwork")
library("tibble")
library("forcats")
library("scales")
library("gt")
library("rstan")
library("bayestestR")
library("kableExtra")

```


## Abstract

## Introduction

Humans are inherently social beings, and our daily interactions with others profoundly shape our affect. A single encounter, whether a harsh critique in an interview or an unexpectedly warm conversation, can significantly impact how we feel. Despite the central role social experiences play in our emotional lives, the mechanisms underlying the relationship between these experiences and momentary mood remain vastly underexplored. In this study, we investigate the hypothesis that social surprises, the discrepancy between what we expect from a social interaction and the actual outcome, play a key role in shaping momentary mood. We reverse-translate elements of clinical theory and observation by introducing a novel experimental and computational framework to test this hypothesis in adolescents and adults, including individuals with elevated symptoms of social anxiety and depression.

This centrality of social experiences in shaping our affective lives is rooted in our evolutionary history. Human survival has long depended on our ability to navigate complex social environments. Several evolutionary theories suggest that traits such as cooperation, altruism, and culture emerged because they provided advantages in group living, such as cooperative foraging and shared child-rearing [@trivers1971; @tomasello2014]. In line with this, human emotions are believed to have evolved to help us address social challenges and promote cohesion and cooperation, ultimately enhancing our chances of survival [e.g., @nesse1990]. Given the role of social behaviour in human evolution, it is unsurprising that social relationships have a profound impact on people’s quality of life and overall mental and physical health [@kuczynski2020; @wickramaratne2022; @cacioppo2014]. Notably, many psychopathologies are closely tied to interpersonal difficulties, particularly during adolescence [@fett2015; @lamblin2017]. Impairments in social functioning are especially evident in mood and anxiety disorders, with Social Anxiety Disorder (SAD) being a key example [@saris2017; @wittchen2000]. Exploring how social interactions shape affect can thus yield valuable insights into human functioning, both in mental health and in disorder.

One promising approach to unpacking this relationship is through computational modelling. Recent advances in this field have begun to uncover the mechanisms of self-reported momentary mood. More specifically, research has highlighted a central role for reward prediction errors (RPEs), in shaping momentary fluctuations in mood [@rutledge2014; @keren2021]. According to this framework, mood can be explained by integrating over the history of events, especially RPEs, that occur in our environment. Positive RPEs, where outcomes exceed expectations, tend to elevate mood, while negative RPEs, where outcomes fall short, tend to suppress it. For example, an unexpected bonus at work might boost mood, whereas receiving the same bonus when expecting a bigger one, could lead to disappointment and to a lower mood. Computational modelling provides a powerful tool for capturing how past experiences shape current mood, including formalising the extent to which past events continue to exert influence over time. For instance, incorporating a forgetting factor allows models to account for the greater weight often given to more recent experiences; known as the recency bias. Extending this research into the social domain is essential as it will allow us to examine whether similar computational mechanisms underlie mood dynamics across different reward types.

Much of the computational literature on momentary mood has focused on the happy–unhappy spectrum, while other types of mood are largely understudied. Specifically, while the processes involved in pathological anxiety, such as in SAD have been extensively studied, the computations involved in anxious mood remain poorly understood. Clinical theory offers valuable insight here. The notion of belief disconfirmation, closely related to prediction error, is foundational in cognitive therapy for anxiety disorders [@clark1995; @salkovskis2007]. For example, treatment for SAD involves generating positive prediction errors that arise when individuals are asked to track their expectations against the outcomes of social interactions during therapy [@clark1999]. This therapeutic principle can be ‘reverse-translated’ to guide experimental investigations into the mechanisms of momentary anxiety, particularly within social contexts.

In this article, we address key gaps in the literature by examining the computations underlying momentary happy and anxious mood in the context of social interactions. Specifically, we extend computational models of mood into the social domain, incorporate anxious affect, and investigate how these processes vary across symptom dimensions. Given the heightened salience of social rewards and punishments in adolescents [@foulkes2016], as well as the rise in mental health problems related to interpersonal difficultiles in this age group [@lamblin2017], we recruited adolescents aged 14-18 through schools, as well as adults aged 18-45 through the local community and Prolific. We developed a novel experimental paradigm designed to elicit social PEs in which participants interacted with virtual players and were asked to report their momentary happy and anxious mood in response to social feedback. This task was co-designed with a youth advisory group to ensure clarity and engagement for younger participants. We preregistered the hypothesis (<https://osf.io/73zsg/>) that social PEs would be central to affective responses and, more specifically, would be positively associated with happy mood and negatively with anxious mood. To test this, we fitted and compared a series of hierarchical Bayesian computational models that systematically varied in their inclusion and specification of social PEs, expectations, and outcomes. Crucially, this included a model without social PEs, allowing us to directly evaluate the added explanatory value of social PEs relative to a plausible alternative. Our findings suggest that both happy and anxious mood are shaped by immediate social feedback, as well as by the history positive and negative social PEs. In exploratory analyses, we extended the best-fitting model to assess how social anxiety and depressive symptoms modulated these computational parameters. Our results showed that people with higher social anxiety symptoms exhibit a stronger influence of social feedback on their momentary mood and anxiety. Further, individuals with higher depressive symptoms showed a bigger effect of negative social PEs on their mood. This could suggest that individuals at risk for social anxiety and depression are more susceptible to social appraisals when reporting their momentary affect. These findings offer insight into how affective dynamics may become dysregulated in psychopathology and point to potential early markers of risk.

## Results

### Participants

We analysed data from 185 participants aged 14–45 years, recruited from three different sources: an online platform (n = 97), the University College London community (n = 43), and from schools (n = 44).

### Experimental setup 

Participants first completed questionnaires assessing social anxiety and depressive symptoms. Depending on their age group, these included the Liebowitz Social Anxiety Scale – Self-Report (LSAS; @fresco2001), the Centre for Epidemiologic Studies Depression Scale (CES-D; @radloff1977), the LSAS for Children and Adolescents – Self-Report (LSAS-CA; @leigh2022), and the Revised Child Anxiety and Depression Scale (RCADS; @chorpita2000). They then completed an online task simulating socially evaluative interactions (see Fig.1). They were told that four different “virtual players” would rate them after they described images aloud while being video recorded. Each trial began with the presentation of the virtual player assigned to that trial, followed by the participant’s prediction of how well they expected to be rated. Participants then described the image for 15 seconds and received feedback from the virtual player on a scale from 0 to 100. Afterward, they reported their momentary mood and anxiety. The virtual players varied in their level of criticality, and feedback was manipulated to generate a range of social prediction errors (PEs), including negative (PE^−^), moderate positive (PE^+^), strong positive (PE^++^), and neutral (PE^N^), based on each player’s typical rating behaviour. Trial order, feedback, and stimuli were randomized.


```{r experimental set up figure}
#| label: fig-experimental-setup
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Structure of a trial in the experimental task. Participants interacted with four different virtual players throughout the task. During the first four trials, each virtual player was introduced alongside a histogram illustrating their rating tendencies, designed to induce expectations about how critical each player would be. From the fifth trial onward, only the name and picture of the virtual player providing the upcoming rating were shown. After this presentation, participants rated how well they expected to perform on that trial (*Prediction*), then described a picture to the virtual player for 15 seconds while being video recorded. They subsequently received a score out of 100 from the virtual player (*Feedback*) and reported their current levels of happy and anxious mood."
#| fig-title: "Fig 1. Experimental Task"
#| fig-cap-location: bottom

include_graphics("experimental task design.pdf")

```


### Momentary anxiety and mood were best explained by asymmetric PEs and social feedback amount.

Out of the eight computational models compared, the best-fitting one for both mood and anxiety, included an effect of social feedback and asymmetric effects for positive and negative prediction errors (PEs). Crucially, this model outperformed alternatives that excluded PEs, supporting the idea that social PEs contribute to shaping affect, in line with our hypothesis. Social feedback was modelled as the outcome of the current trial, while the PE terms were represented as recency-weighted sums of all prior positive and negative PEs, respectively. Specifically, self-reported mood and anxiety at trial $t$ for individual $i$ was modelled as

$$
Mood_{it} = \beta_{0i} +\beta_{1i}\cdot  \sum_{j=1}^{t} \gamma^{t - j} \cdot PE_{pos,j} + \beta_{2i}\cdot \sum_{j=1}^{t} \gamma^{t - j} \cdot PE_{neg,j}  + \beta_{3i}\cdot O_t\
$$ {#eq-model_8_mood}

$$
Anxiety_{it} = \beta_{0i} +\beta_{1i}\cdot  \sum_{j=1}^{t} \gamma_i^{t - j} \cdot PE_{pos,j} + \beta_{2i}\cdot \sum_{j=1}^{t} \gamma_i^{t - j} \cdot PE_{neg,j}  + \beta_{3i}\cdot O_t\
$$ {#eq-model_8_anxiety}

where $\beta_{0i}$ represents the individual-specific baseline of mood or anxiety, and $\beta_{1i}$ and $\beta_{2i}$ capture the sensitivity of individual $i$ to the history of positive and negative PEs, respectively. The parameter $\gamma_i^{t - j}$ is a forgetting factor that determines the influence of prior trials on affect. $O_t$ represents the social feedback on trial t, and $\beta_{3i}$ captures its immediate effect on momentary affect for participant $i$.


```{r Mood and anxiety model fits for two participants. }
#| label: fig-predicted-vs-reported
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Reported and predicted mood and anxiety across trials for two participants. Each panel shows z-scored values across trials, with mood plotted in the left column and anxiety in the right column. Rows represent individual participants. Reported responses are shown in grey, predicted mood in blue, and predicted anxiety in red. Predicted values are derived from the posterior mean of a hierarchical Bayesian model."
#| fig-title: "Mood and anxiety model fits for two participants."
#| fig-cap-location: bottom

include_graphics("predicted_vs_reported_affect.pdf")

```


### Group-Level Parameter Estimates

**Social Feedback Effects (**$\beta_{3}$**)**\
Social feedback had a strong effect on both mood and anxiety. For momentary mood, social feedback had a substantial positive effect (mean **(**$\beta_{3}$**)** = 0.22, 95% HDI \[0.19, 0.26\]), indicating that more positive social feedback was associated with increased mood. In contrast, for momentary anxiety, social feedback exerted a negative effect (mean **(**$\beta_{3}$**)** = -0.09, 95% HDI \[-0.11, -0.07\]), suggesting that more positive social feedback was associated with reduced anxiety.

**Positive Prediction Error Effects (**$\beta_{1}$**)**\
The effect of positive PEs varied across mood and anxiety models. For momentary mood, the effect was small and not substantial (mean **(**$\beta_{1}$**)** = 0.01, 95% HDI \[0.00, 0.03\]). However, for momentary anxiety, there was a small but substantial negative effect of positive PEs (mean **(**$\beta_{1}$**)** = -0.04, 95% HDI \[-0.06, -0.03\]), indicating that experiencing outcomes better than expected was linked to reduced anxiety.

**Negative Prediction Error Effects (**$\beta_{2}$**)**\
Negative PEs did not show a strong association with momentary mood (mean **(**$\beta_{2}$**)** = -0.01, 95% HDI \[-0.02, 0.01\]). For momentary anxiety, however, there was a small but substantial positive effect (mean **(**$\beta_{2}$**)** = 0.04, 95% HDI \[0.02, 0.06\]), suggesting that worse-than-expected outcomes were associated with increased anxiety.

**Forgetting Factor (**$\gamma$**)**\
The forgetting factor $\gamma$ determines how much influence past prediction errors (PEs) have on current affect, with values bounded between 0 and 1. A value of $\gamma = 0$ implies full recency, where only the most recent trial influences affect, while $\gamma = 1$ implies equal weighting of all past trials, regardless of their temporal distance. The group-level estimate of $\gamma$ was 0.93 for both mood (95% HDI \[0.91, 0.95\]) and anxiety (95% HDI \[0.92, 0.95\]), indicating that past trials have a fairly long-lasting impact on current affect.

These results partially support our hypothesis that social surprises, operationalized here as PEs, play a key role in shaping momentary mood and anxiety. While the best-fitting model included terms for both positive and negative PEs, and outperformed models without them, only social feedback and not the PE themselves showed a substantial effect on mood at the group level. In contrast, anxiety was modulated by both positive and negative PEs, indicating that momentary anxiety is more sensitive to social surprises than mood in this task context.

### Moderation of effects by social anxiety symptoms

To assess whether social anxiety symptoms (SA), as measured by the LSAS, moderated any of the model parameters, we examined interaction terms from the hierarchical Bayesian models predicting momentary anxiety and mood. For both mood and anxiety, the interaction term for social feedback , $\beta_{3 \cdot SA}$ , showed the most robust effect. For anxiety, this interaction was negative (mean = –0.04, 95% HDI [–0.06, –0.02], see @param_distributions), suggesting that higher SA amplified the influence of social feedback on decreasing anxiety. In contrast, for mood, the interaction was positive (mean = 0.04, 95% HDI [0.00, 0.07], see @param_distributions), indicating that SA also strengthened the positive impact of social feedback on mood.

Other interaction terms between SA and the intercept ( $\beta_{0 \cdot SA}$) , positive PEs ($\beta_{1 \cdot SA}$), negative PEs ($\beta_{2 \cdot SA}$), and the forgetting factor ($\beta_{\gamma \cdot SA}$) had credible intervals that overlapped zero for both outcomes, suggesting inconclusive or negligible moderation effects. Similarly, the main effects of SA on momentary anxiety (mean = 0.22, 95% HDI \[–0.49, 0.92\]) and mood (mean = –0.16, 95% HDI \[–0.81, 0.56\]) were also uncertain.

To complement the model-based findings, we computed the posterior distribution of Pearson correlations between each participant-level parameter estimates and SA scores. The parameter for social feedback ($\beta_3$) showed a strong negative correlation with SA in predicting anxiety (mean r = –0.29, 95% CI [–0.35, –0.23], Pr(r \< 0) = 100%; see @posterior_corr_distributions), and a moderate positive correlation in predicting mood (mean r = 0.16, 95% CI [0.11, 0.19], Pr(r \> 0) = 100%; see @posterior_corr_distributions). These results provide further support for a moderation of the influence of social feedback on momentart affect, by SA. Correlations for all other parameters were weaker and had posterior intervals that included zero.

### Moderation of effects by depression symptoms

To assess whether depression symptoms (DEP), as measured by the RCADS in the student sample and the CES-D in all other samples (z-scored within each sample prior to modelling), moderated any of the model parameters, we examined interaction terms from the hierarchical Bayesian models predicting momentary anxiety and mood. For both mood and anxiety models, the interaction terms between DEP and the intercept ($\beta_{0 \cdot SA}$), positive PEs ($\beta_{1 \cdot SA}$), negative PEs ($\beta_{2 \cdot SA}$), social feedback ($\beta_{3 \cdot SA}$) and the forgetting factor ($\beta_{\gamma \cdot SA}$ )had credible intervals that overlapped zero, suggesting inconclusive or negligible moderation effects. Similarly, the main effects of DEP on momentary anxiety (mean = 0.17, 95% HDI \[–0.49, 0.87\]) and mood (mean = –0.10, 95% HDI \[–0.85, 0.53\]) were also uncertain.

We also computed the posterior distribution of Pearson correlations between each participant-level parameter estimates and DEP scores. According to this analysis, the parameter for social feedback ($\beta_2$ ) showed a moderate negative correlation with DEP in predicting mood (mean r = –0.18, 95% CI \[–0.35, –0.01\], Pr(r \< 0) = 97.9%). This suggest that individuals with higher DEP, exhibited a stronger negative effect of negative PEs on their mood. Correlations for all other parameters were weaker and had posterior intervals that included zero.


```{r parameter distributions by SA and DEP group}
#| label: param_distributions
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Posterior distributions by SA and DEP groups of A) Social Feedback for mood , B) Social Feedback for anxiety and C) Negative PE for mood. "
#| fig-cap-location: bottom

asymmPE_simple_Outcome_mood_DEP_fit<- readRDS("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/R code/Computational modelling/Full_scale_data_comp_modelling_results/asymmPE_simple_Outcome_mood_DEP_fit.rds")
posterior_DEP_mood <- rstan::extract(asymmPE_simple_Outcome_mood_DEP_fit)

asymmPE_simple_Outcome_anx_SA_LSAS_fit<- readRDS("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/R code/Computational modelling/Full_scale_data_comp_modelling_results/asymmPE_simple_Outcome_anx_SA_LSAS_fit.rds")
posterior_SA_anx<- rstan::extract(asymmPE_simple_Outcome_anx_SA_LSAS_fit)

asymmPE_simple_Outcome_mood_SA_LSAS_fit<- readRDS("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/R code/Computational modelling/Full_scale_data_comp_modelling_results/asymmPE_simple_Outcome_mood_SA_LSAS_fit.rds")
posterior_SA_mood <- rstan::extract(asymmPE_simple_Outcome_mood_SA_LSAS_fit)

data <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/surprise_task_merged_data.csv")

# Ensure data is sorted by Random_ID and trial within each participant
data <- data[order(data$Random_ID), ]

# Extract unique participant IDs in order
participant_ids <- unique(data$Random_ID)
data$LSAS_Total <- scale(data$LSAS_Total)[, 1]

#DEP ~ W_Neg for mood
Dep_info <- data %>%
  group_by(Random_ID) %>%
  summarise(    
    Dep = first(Depression_score_scaled),
    Dep_Threshold = first(Depression_Threshold)
  ) %>%
  arrange(Random_ID)

SA_info <- data %>%
  group_by(Random_ID) %>%
  summarise(    
    SA = first(LSAS_Total))%>%
  arrange(Random_ID)

# Helper to get high/low group parameter samples
extract_param_by_group <- function(posterior, param_mu, beta_param, SA_vals, sa_cutoff) {
  n_samples <- length(posterior[[param_mu]])
  group_labels <- ifelse(SA_vals >= sa_cutoff, "High SA", "Low SA")
  
  low_vals  <- SA_vals[SA_vals < sa_cutoff]
  high_vals <- SA_vals[SA_vals >= sa_cutoff]
  
  low  <- rowMeans(matrix(posterior[[param_mu]], nrow = n_samples, ncol = length(low_vals)) +
                     posterior[[beta_param]] %o% low_vals)
  high <- rowMeans(matrix(posterior[[param_mu]], nrow = n_samples, ncol = length(high_vals)) +
                     posterior[[beta_param]] %o% high_vals)
  
  df <- data.frame(
    value = c(low, high),
    group = rep(c("Low SA", "High SA"), each = n_samples)
  )
  
  return(df)
}

# Set SA cutoff and get SA vector
sa_cutoff <- -0.90
SA_vals <- sapply(participant_ids, function(id) {
  unique(data$LSAS_Total[data$Random_ID == id])[1]
})

Dep_info <- data %>%
  group_by(Random_ID) %>%
  summarise(    
    Dep = first(Depression_score_scaled),
    Dep_Threshold = first(Depression_Threshold)
  ) %>%
  arrange(Random_ID)
group_labels <- ifelse(Dep_info$Dep_Threshold == 1, "High Dep", "Low Dep")
low_Dep_vals  <- Dep_info$Dep[Dep_info$Dep_Threshold == 0]
high_Dep_vals <- Dep_info$Dep[Dep_info$Dep_Threshold == 1]


# Number of posterior samples
n_samples <- length(posterior_DEP_mood$intercept)

# Same for w2
w_neg_low  <- rowMeans(matrix(posterior_DEP_mood$w_neg_mu, nrow = n_samples, ncol = length(low_Dep_vals)) +
                     posterior_DEP_mood$beta_w_neg %o% low_Dep_vals)

w_neg_high <- rowMeans(matrix(posterior_DEP_mood$w_neg_mu, nrow = n_samples, ncol = length(high_Dep_vals)) +
                    posterior_DEP_mood$beta_w_neg %o% high_Dep_vals)


# Helper function for mean and 95% CI
summarize_param <- function(low, high) {
  low_mean  <- mean(low)
  high_mean <- mean(high)
  diff <- high - low
  diff_mean <- mean(diff)
  
  low_CI  <- quantile(low, probs = c(0.025, 0.975))
  high_CI <- quantile(high, probs = c(0.025, 0.975))
  diff_CI <- quantile(diff, probs = c(0.025, 0.975))
  
  data.frame(
    `Low Dep Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", low_mean,  low_CI[1],  low_CI[2]),
    `High Dep Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", high_mean, high_CI[1], high_CI[2]),
    `High - Low Mean (95% CI)` = sprintf("%.2f [%.2f, %.2f]", diff_mean, diff_CI[1], diff_CI[2])
  )
}


# Prepare for plotting
posterior_df_mood <- data.frame(
  w_neg_low, w_neg_high
)

# A) w1 from posterior_SA_mood
df_A <- extract_param_by_group(posterior_SA_mood, "w1_mu", "beta_w1", SA_vals, sa_cutoff)

plot_A <- ggplot(df_A, aes(x = value, fill = group, color = group)) +
  geom_density(alpha = 0.8) +  # Full opacity for both groups
  geom_vline(data = df_A %>% group_by(group) %>% summarise(m = mean(value)), 
             aes(xintercept = m, color = group), linetype = "dashed") +
  scale_fill_manual(values = c("Low SA" = "#85C3D6", "High SA" = "#0072B2")) +  # Lighter blue for low SA
  scale_color_manual(values = c("Low SA" = "#85C3D6", "High SA" = "#0072B2")) +  # Lighter blue for low SA
  labs(title = "A) Social Feedback (Mood)", x = expression(beta[3]), y = "Density") +
  theme_minimal(base_size = 14)

# B) w1 from posterior_SA_anx
df_B <- extract_param_by_group(posterior_SA_anx, "w1_mu", "beta_w1", SA_vals, sa_cutoff)

plot_B <- ggplot(df_B, aes(x = value, fill = group, color = group)) +
  geom_density(alpha = 0.8) +  # Full opacity for both groups
  geom_vline(data = df_B %>% group_by(group) %>% summarise(m = mean(value)), 
             aes(xintercept = m, color = group), linetype = "dashed") +
  scale_fill_manual(values = c("Low SA" = "#F2B7B6", "High SA" = "#C44E52")) +  # Lighter red for low SA
  scale_color_manual(values = c("Low SA" = "#F2B7B6", "High SA" = "#C44E52")) +  # Lighter red for low SA
  labs(title = "B) Social Feedback (Anxiety)", x = expression(beta[3]), y = "Density") +
  theme_minimal(base_size = 14)

# C) w_neg from posterior_DEP_mood
# Prepare dataframe for plotting
df_C <- data.frame(
  value = c(w_neg_low, w_neg_high),
  group = rep(c("Low DEP", "High DEP"), each = n_samples)
)


# Plot C: Negative PE for Mood
plot_C <- ggplot(df_C, aes(x = value, fill = group, color = group)) +
  geom_density(alpha = 0.8) +  # Full opacity for both groups
  geom_vline(data = df_C %>% group_by(group) %>% summarise(m = mean(value)), 
             aes(xintercept = m, color = group), linetype = "dashed") +
  scale_fill_manual(values = c("Low DEP" = "#85C3D6", "High DEP" = "#0072B2")) +  # Lighter blue for low DEP
  scale_color_manual(values = c("Low DEP" = "#85C3D6", "High DEP" = "#0072B2")) +  # Lighter blue for low DEP
  labs(title = "C) Negative PE (Mood)", x = expression(beta[2]), y = "Density") +
  theme_minimal(base_size = 14)

# Arrange A + B / C using patchwork
combined_plot <- (plot_A | plot_B) / plot_C

# Display
print(combined_plot)

```

```{r Posterior correlation distributions}
#| label: posterior_corr_distributions
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Posterior correlation distributions for A) Social Feedback and SA for anxiety, B) Social Feedback and SA for mood and C) Negative PE and DEP for mood. "
#| fig-cap-location: bottom


# Compute posterior samples of correlation for w_neg
w_neg_samples <- sapply(1:nrow(posterior_DEP_mood$w_neg), function(i) {
  cor(posterior_DEP_mood$w_neg[i, ], Dep_info$Dep)
})

# Prepare data frame
w_neg_df <- data.frame(r = w_neg_samples)

# Compute summary stats
hdi_w_neg <- HDInterval::hdi(w_neg_samples, credMass = 0.95)
mean_r <- mean(w_neg_samples)
pr_less_than_zero <- mean(w_neg_samples < 0)


#SA ~ W1 for anxiety
# Compute posterior samples of correlation for w_1
w1_samples_anx <- sapply(1:nrow(posterior_SA_anx$w1), function(i) {
  cor(posterior_SA_anx$w1[i, ], SA_info$SA)
})

# Prepare data frame
w1_SA_df_anx <- data.frame(r = w1_samples_anx)

# Compute summary stats
hdi_w1_anx <- HDInterval::hdi(w1_samples_anx, credMass = 0.95)
mean_r_w1_anx <- mean(w1_samples_anx)
pr_less_than_zero_w1_anx <- mean(w1_samples_anx < 0)

#SA ~ W1 for mood
# Compute posterior samples of correlation for w_1
w1_samples_mood <- sapply(1:nrow(posterior_SA_mood$w1), function(i) {
  cor(posterior_SA_mood$w1[i, ], SA_info$SA)
})

# Prepare data frame
w1_SA_df_mood <- data.frame(r = w1_samples_mood)

# Compute summary stats
hdi_w1_mood <- HDInterval::hdi(w1_samples_mood, credMass = 0.95)
mean_r_w1_mood <- mean(w1_samples_mood)
pr_less_than_zero_w1_mood <- mean(w1_samples_mood < 0)

# Color mappings
color_anx <- "#C44E52"
color_mood <- "#0072B2"

# High = solid, Low = transparent
fill_colors <- list(
  "High SA"  = color_anx,
  "Low SA"   = scales::alpha(color_anx, 0.3),
  "High DEP" = color_mood,
  "Low DEP"  = scales::alpha(color_mood, 0.3)
)


# --- Plot A: SA (anxiety) ---
p_SA_anx_labeled <- ggplot(w1_SA_df_anx, aes(x = r)) +
  geom_density(fill = "#C44E52", alpha = 0.8, color = NA) +
  geom_vline(xintercept = mean_r_w1_anx, linetype = "dashed", color = "black", size = 0.6) +
  geom_vline(xintercept = hdi_w1_anx, linetype = "dotted", color = "gray30", size = 0.5) +
  annotate("text", x = mean_r_w1_anx, y = 10, label = paste0("r = ", round(mean_r_w1_anx, 2)),
           vjust = -0.5, hjust = -0.1, size = 4.5) +
  labs(
    tag = "B",
    title = "Social feedback ~ SA",
    x = "Correlation coefficient (r)",
    y = "Density"
  ) +
  theme_classic(base_size = 12) +
  theme(
    plot.title = element_text(size = 15, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    axis.line = element_line(size = 0.5, color = "black")
  )

# --- Plot B: SA (mood) ---
p_SA_mood_labeled <- ggplot(w1_SA_df_mood, aes(x = r)) +
  geom_density(fill = "#0072B2", alpha = 0.8, color = NA) +
  geom_vline(xintercept = mean_r_w1_mood, linetype = "dashed", color = "black", size = 0.6) +
  annotate("text", x = mean_r_w1_mood, y = 15, label = paste0("r = ", round(mean_r_w1_mood, 2)),
           vjust = -0.5, hjust = -0.1, size = 4.5) +
  labs(
    tag = "A",
    title = "Social feedback ~ SA",
    x = "Correlation coefficient (r)",
    y = "Density"
  ) +
  theme_classic(base_size = 12) +
  theme(
    plot.title = element_text(size = 15, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    axis.line = element_line(size = 0.5, color = "black")
  )

# --- Plot C: DEP (mood) ---
p_DEP_labeled <- ggplot(w_neg_df, aes(x = r)) +
  geom_density(fill = "#0072B2", alpha = 0.8, color = NA) +
  geom_vline(xintercept = mean_r, linetype = "dashed", color = "black", size = 0.6) +
  geom_vline(xintercept = hdi_w_neg, linetype = "dotted", color = "gray30", size = 0.5) +
  annotate("text", x = mean_r , y = 3, label = paste0("r = ", round(mean_r, 2)),
           vjust = -0.5, hjust = -0.1, size = 4.5) +
  labs(
    tag = "C",
    title = "Negative PE ~ DEP",
    x = "Correlation coefficient (r)",
    y = "Density"
  ) +
  theme_classic(base_size = 12) +
  theme(
    plot.title = element_text(size = 15, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    axis.line = element_line(size = 0.5, color = "black")
  )

# === Create legend patch ===
legend_df <- tibble(
  x = c(1, 2),
  group = factor(c("Mood models (B, C)", "Anxiety model (A)")),
  color = c("#0072B2", "#C44E52")
)

legend_plot <- ggplot(legend_df, aes(x = x, y = 1, fill = group)) +
  geom_bar(stat = "identity", position = "stack", width = 1, alpha = 0.8) +
  scale_fill_manual(values = setNames(legend_df$color, legend_df$group)) +
  theme_void() +
  theme(
    legend.position = "right",
    legend.title = element_blank(),
    legend.text = element_text(size = 10)
  ) +
  guides(fill = guide_legend(override.aes = list(alpha = 0.8)))

legend_patch <- wrap_elements(get_legend(legend_plot))

# === Layout using patchwork ===
layout_design <- "
AB
CL
"

combined_plot <- (
  p_SA_mood_labeled +
  p_SA_anx_labeled  + 
    p_DEP_labeled + 
    legend_patch
) + 
  plot_layout(design = layout_design) +
  plot_annotation(tag_levels = NULL)

combined_plot
```


## Discussion

-   notes: Interaction effect for Social Feedback x SA can be interpreted as a susceptibility to PE and a target opportunity for treatment.

## **Methods**

### Participants

We recruited 185 participants aged 14–45 years from three different sources: an online platform, UCL community, and schools. Based on our preregistered power analyses using pilot data, which included parametric simulations for detecting the effect of social prediction errors on mood and anxiety and bootstrapping for Bayesian model comparison, both conducted to ensure at least 80% power, our final sample of 185 participants exceeds the required sample sizes (n ≈ 30), indicating that the study is well powered.

#### Online Participants

We recruited 106 online participants between the ages of 18-45 using Prolific ([www.prolific.com](https://prolific.com/)). See Table 1 for participants demographic information. Eight participants were excluded due to poor engagement with the task, as evidenced by their video recordings. We required that our participants be adults living in the United Kingdom or the United States, that they speak fluent English, have no cognitive impairment or dementia, and that over 90% of their previous jobs have been approved. We also required that participants had not taken part in any of our pilot studies (which were similar to this one). Participants were paid at a rate of £9/hr as compensation for their time.

#### UCL Community Participants

We recruited 47 participants between the ages of 18-25 from the University College London (UCL) community, using posters and through the UCL psychology subject pool (SONA). Four participants were excluded due to poor engagement with the task, as evidenced by their video recordings. Upon registration, participants were invited to book a testing session, which they were instructed to complete in a quiet and private space. At the time of the testing session, they received a link to the online task. Participants were compensated with a £10 Love2shop or Amazon voucher for their time.

#### School Participants

We recruited 49 participants between the ages of 14-25 through schools (via physical flyers or via school newsletters). Five participants were excluded due to poor engagement with the task, as evidenced by their video recordings. Schools were recruited either by direct contact or by advertising through the Anna Freud school network newsletter. For students under the age of 16, parental opt-out consent was required. Upon registration, participants were invited to book a testing session, which they were instructed to complete in a quiet and private space. At the time of the testing session, they received a link to the online task. Participants were compensated with a £10 Love2shop voucher for their time. As an additional incentive, schools were also offered talks on mental health, careers in psychology or related topics.


```{r summary demographics tables}
#| label: tbls-demographics-summary
#| tbl-cap: "Summary demographics table"
#| tbl-cap-location: top
#| echo: false
#| warning: false
#| message: false

df <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/merged_data_demographics.csv")
# --- STEP 1: Prepare and clean dataset ---
df <- df %>%
  mutate(
    dataset_group = case_when(
      dataset %in% c("Pilot_21", "pro_18_25") ~ "Prolific participants aged 18–25",
      dataset == "pro_26_45" ~ "Prolific participants aged 26–45",
      dataset == "school" ~ "School participants aged 14-18",
      dataset == "local_com" ~ "Local Community aged 18–25",
      TRUE ~ "Other"
    ),
    
    # Flag gender identity differing from sex
    Gender_differs = ifelse(!is.na(Gender_other) & Gender_other != "", 1, 0),
    
    # Clean sex and ethnicity
    Sex = factor(Sex),
    Ethnicity_combined = case_when(
      !is.na(ethnicity_other) & ethnicity_other != ""  ~ paste0("Other: ", ethnicity_other),
      TRUE ~ as.character(Ethnicity)
    )
    
  )

# Set the order of dataset groups
df$dataset_group <- factor(df$dataset_group,
                           levels = c(
                             "Prolific participants aged 18–25",
                             "Prolific participants aged 26–45",
                             "Local Community aged 18–25",
                             "School participants aged 14-18"
                           ))


# Group low-frequency ethnicities into "Other"
df$Ethnicity_combined <- fct_lump(factor(df$Ethnicity_combined), n = 5)

# Ensure diagnosis variables only counted if prior question was "Yes"
df <- df %>%
  mutate(
    Depression = ifelse(Mental_health_diagnosis == "Yes", Depression, NA),
    Anxiety = ifelse(Mental_health_diagnosis == "Yes", Anxiety, NA),
    ADHD = ifelse(Mental_health_diagnosis == "Yes", ADHD, NA),
    ASD = ifelse(Mental_health_diagnosis == "Yes", ASD, NA)
  )

# --- STEP 2: Main demographics table ---

demographics_summary <- df %>%
  group_by(dataset_group) %>%
  summarise(
    N = n(),
    Age = paste0(round(mean(Age, na.rm = TRUE), 1), " (", round(sd(Age, na.rm = TRUE), 1), ")"),
    
    Female = paste0(sum(Sex == "Female", na.rm = TRUE), " (", percent(mean(Sex == "Female", na.rm = TRUE), accuracy = 0.1), ")"),
    Male = paste0(sum(Sex == "Male", na.rm = TRUE), " (", percent(mean(Sex == "Male", na.rm = TRUE), accuracy = 0.1), ")"),
    Depression = paste0(sum(Depression == 1, na.rm = TRUE), " (", percent(sum(Depression == 1, na.rm = TRUE) / n(), accuracy = 0.1), ")"),
    Anxiety = paste0(sum(Anxiety == 1, na.rm = TRUE), " (", percent(sum(Anxiety == 1, na.rm = TRUE) / n(), accuracy = 0.1), ")")) %>%
  ungroup()

# Display demographics table
demographics_summary %>%
  gt() %>%
  tab_header(title = "Demographic Characteristics by Dataset Group") %>%
  cols_label(
    dataset_group = "Dataset Group",
    N = "N",
    Age = "Age (Mean ± SD)",
    Female = "Female (Sex)",
    Male = "Male (Sex)",
    Depression = "Depression",
    Anxiety = "Anxiety"
  ) 

```


### Questionnaires and Experimental Task

The online questionnaires and experimental task were created and hosted on Gorilla Experiment Builder ([www.gorilla.sc](http://www.gorilla.sc/)). The experiment took approximately 50 minutes to complete. Participants first provided informed consent as approved by UCL’s Research Ethics Committee. Participants then completed a series of questionnaires. First, they completed a survey about their demographics, mental health diagnoses and psychotropic medication use.  Then, participants completed the Mini-Social Phobia Inventory (Mini-SPIN; @connor2001), the Generalized Anxiety Disorder 7-item Scale (GAD-7; @spitzer2006), and the Affective Reactivity Index (ARI; @stringaris2012). School participants additionally completed the Lebowitz Social Anxiety Scale for Children and Adolescents – Self-Report (LSAS-CA; @leigh2022) and the Revised Child Anxiety and Depression Scale (RCADS; @chorpita2000). Online and UCL community participants completed the adult version of the Lebowitz Social Anxiety Scale – Self-Report (LSAS; @fresco2001), the Centre for Epidemiologic Studies Depression Scale (CES-D; @radloff1977), the Adult ADHD Self-Report Scale (ASRS; @kessler2005), the Drug Use Disorders Identification Test (DUDIT; @berman2002), the Alcohol Use Disorders Identification Test (AUDIT; @saunders1993), and the Body Image Questionnaire (BIQ; @cash1995). In the present study, we report analyses only from the Mini-SPIN and CES-D and the low mood RCADS subscale.

After completing the mental health questionnaires and passing two attention checks, participants proceeded to an experimental task. In this task, participants were informed that they would practice speaking to others and receive performance ratings from “virtual players” based on how well they came across. The task consisted of 48 trials. On each trial, participants were first shown a picture of the virtual player who would be providing feedback for that trial. For the first trial with each of the four virtual players, the image was accompanied by a histogram depicting that player’s previous ratings of others, in order to establish an initial expectation regarding the player’s level of criticality. The four virtual players varied in their rating style, ranging from very easy-going to highly critical.

After viewing the virtual player, participants were asked to report their expectation regarding how they would be rated on that specific trial, on a scale from 0 to 100. Next, they were shown a picture and instructed to describe it to the virtual player while being video recorded for 15 seconds. Following this, they received feedback from the virtual player in the form of a percentage score. Finally, participants rated their current mood and anxiety levels on a scale from 0 to 100 (with 0 indicating “Very unhappy” or “Very relaxed,” and 100 indicating “Very happy” or “Very nervous/uncomfortable,” respectively).

To induce a variety of social PEs, we manipulated the feedback with the aim of generating two positive (PE^+^), two bigger positive (PE^++^), four negative (PE^−^) and four neutral PEs (PE^N^; indicating no PE) per virtual player. These were based on the virtual player’s histogram mean. To do this, we used the mean of the virtual players’ histograms (29, 37, 63, 71). PE^+^ feedback was generated by adding a randomly sampled value (from a normal distribution with mean = 12, SD = 3, range = 12–20) to the histogram mean. PE^++^ feedback was generated by further adding 10 ±1 to the PE+ value. PE^−^ feedback was generated by subtracting a similarly sampled value from the histogram mean. PE^N^ feedback was set as either the exact histogram mean or one point above or below it. The order of trials with each virtual player, the feedback received, the mood and anxiety rating prompts, and the picture stimuli were all randomized across participants and trials.

This task was developed in collaboration with members of a Young People Advisory Group (YPAG), who provided feedback on multiple pilots. Their input helped refine the phrasing of task instructions and questions to ensure accessibility for young people. Additionally, they evaluated the believability of the virtual players across several iterations of the task. Evidence from piloting suggests the task is socially salient and believable, as indicated by: (1) higher overall anxiety ratings among individuals with elevated social anxiety symptoms, and (2) higher anxiety ratings in pilots that included a video recording component compared to those without it (see Supplement).

### Computational Modelling

Our computational models were chosen based on (1) theoretical considerations and (2) preliminary model comparisons using pilot data (n=37). Eight models were chosen, which were variations of a model developed by @rutledge2014, each differing on their inclusion and specification of social PEs, expectations, and outcomes. This approach allowed us to identify the combination of social appraisal variables that best explained self-reported momentary mood and anxiety ratings in our task and to isolate the unique contribution of each variable.

#### Calculation of social appraisal variables

Within this approach, the outcome amount, $O_t$~*,*~ was defined as the percentage score received by the virtual player on trial $t$.

$$
O_t  = Score_t
$$

Social PEs were defined as the difference between the actual outcomeand the participant-reported expectation, $E_t$, on that trial.

$$
PE_t = O_t - E_t 
$$

In some models, the PE term was divided into separate components for positive and negative social prediction errors, assuming an asymmetric influence on affect.

$$
\text{PE}_{\text{pos}}(t) =\begin{cases}\text{PE}(t), & \text{if } \text{PE}(t) > 0 \\0, & \text{otherwise}\end{cases}
$$

$$
\text{PE}_{\text{neg}}(t) =\begin{cases}\text{PE}(t), & \text{if } \text{PE}(t) > 0 \\0, & \text{otherwise}\end{cases}
$$

#### Hierarchical Bayesian Framework

All models were fit within a hierarchical Bayesian framework using the rstan package (Stan Development Team, 2025) in RStudio (2024). In each model, at least one of the social appraisal variables (i.e., social expectations, prediction errors or outcomes) was modelled as a time-decayed accumulator. Specifically, self-reported mood or anxiety at trial $t$ for individual $i$ was modelled as a normally distributed outcome:

$$
\text{Mood}_{it} \sim \mathcal{N} \left( \beta_{0i} + \beta_{1i} \cdot \sum_{j=1}^{t} \gamma_i^{t-j} \cdot \text{SocialAppraisal}_{ij}, \sigma_i \right)
$$

$$
\text{Anxiety}_{it} \sim \mathcal{N} \left( \beta_{0i} + \beta_{1i} \cdot \sum_{j=1}^{t} \gamma_i^{t-j} \cdot \text{SocialAppraisal}_{ij}, \sigma_i \right)
$$

Here, $Social_Appraisal_{ij}$ denotes the value of the social appraisal on trial *j.* The parameter $\gamma_i \in (0,1)$ is an individual-specific forgetting factor that determines the influence of prior trials on self-reported affect. When, $\gamma = 0$ only the most recent trial contributes to affect, indicating no memory of past events. In contrast, $\gamma = 1$ reflects full accumulation, where all prior social appraisals are weighted equally.

Model estimation was performed via Hamiltonian Monte Carlo, using four independent Markov chains. Each chain produced 2,000 post-warmup samples after an initial 2,000-iteration warmup, yielding a total of 8,000 samples for posterior inference.

The hierarchical structure of the models relied on partial pooling, where individual-level parameters were assumed to be drawn from group-level normal distributions whose means and standard deviations were estimated from the data. This allowed for individual variation while also leveraging population-level structure. For example, individual parameters were specified as follows:

$$
\begin{align}\beta_{0i} &= \mu_{\beta_0} + \epsilon_{\beta_{0i}}  \\\beta_{1i} &= \mu_{\beta_1} + \epsilon_{\beta_{1i}}  \\&\vdots \notag \\\beta_{ni} &= \mu_{\beta_n} + \epsilon_{\beta_{ni}} \\\gamma_i &= \Phi(\mu_{\gamma} + \epsilon_{\gamma_i})  \\\sigma_i &= \exp(\mu_{\sigma} + \epsilon_{\sigma_i}) \end{align}
$$

where $\epsilon_{\theta i} \sim \mathcal{N}(0, \sigma_{\theta}^2)$ are individual-level deviations. Parameters bounded to specific intervals were sampled in an unconstrained latent space and transformed accordingly. Specifically, the forgetting factor γ, which is bounded between 0 and 1, was transformed using a probit link function to ensure it remained within this interval. Standard deviation parameters were constrained to be positive through exponential transformations. Weakly informative priors were applied to all group-level parameters.

#### Summary of Fitted Models

For our first aim, we fit and compared eight different computational models for mood and anxiety, respectively. The models differed in their inclusion and specification of social appraisals, expectations, PEs and Outcomes. Notably, Models 7 and 8 incorporated asymmetric effects for positive and negative PEs. Models 1 and 2 were modified versions of the standard model proposed by @rutledge2014 and the primacy model by @keren2021, respectively, adapted to fit our task-specific data.


```{r models fitted summary table}
#| label: tbl-models-fitted
#| tbl-cap: "Summary table of models compared "
#| tbl-cap-location: top
#| echo: false
#| warning: false
#| message: false

# Create the data frame
model_table <- data.frame(
  Model = 1:8,
  Expectation = c(
    "Recency weighted E", 
    "Primacy weighted E", 
    "Recency weighted E", 
    "-", 
    "-", 
    "Recency weighted E", 
    "-", 
    "-"
  ),
  Prediction_Error = c(
    "Recency weighted PE", 
    "Recency weighted PE", 
    "-", 
    "Recency weighted PE", 
    "PE(t)", 
    "PE(t)", 
    "Asymmetric recency weighted PE", 
    "Asymmetric recency weighted PE"
  ),
  Outcome = c(
    "-", 
    "-", 
    "O(t)", 
    "O(t)", 
    "Recency weighted O", 
    "-", 
    "Recency weighted O", 
    "O(t)"
  )
)

models_table <- flextable(model_table)
models_table <- add_footer_lines(models_table, "Note. E = reported expectation; PE = social prediction error; O = Outcome. ")

models_table
```


### Aim 1: Identify the computations underlying momentary mood and anxiety in our social task

#### Model Comparison and Evaluation

To evaluate and compare the performance of computational models, we employed a combination of information-theoretic and predictive accuracy metrics. Specifically, we used the loo package in R to calculate the Leave-One-Out Information Criterion (LOOIC) and the Widely Applicable Information Criterion (WAIC) to assess out-of-sample predictive fit while accounting for model complexity. Both criteria estimate the expected log predictive density for new data and are particularly well-suited for Bayesian models, with lower values indicating better fit. In addition to these criteria, we computed Mean Squared Error (MSE) and Mean Absolute Error (MAE) as measures of predictive accuracy, reflecting the average squared and absolute deviations between predicted and observed values, respectively. Finally, we included the coefficient of determination (R²) as an indicator of explained variance, providing an interpretable summary of model fit. Together, these complementary metrics allowed for a comprehensive assessment of model performance across both explanatory and predictive dimensions. Posterior predictive checks were conducted on the winning model to verify that the fitted model is compatible with our observed data.

The 95% Bayesian Highest Density Interval (HDI) was calculated for the mean of each group-level parameter. A social appraisal parameter was deemed to have a meaningful influence if its 95% HDI did not cross zero, suggesting a statistically credible effect. 

### Aim 2: Explore how these computations vary with individual differences in mental health symptoms

To examine individual differences in affective dynamics, we extended the winning model by including a main effect of a participant-level moderator (either social anxiety or depression symptoms) and its interaction with all free parameters. These moderators were included as between-subject predictors that modulate both baseline affect and sensitivity to social signals over time.

Specifically, mood and anxiety were modelled as functions of recency-weighted positive and negative prediction errors, outcome feedback, and a participant-specific moderator Mi​ (e.g., LSAS score for social anxiety, RCADS/CES-D score for depression):

$$
\begin{gather*}\text{Mood}_{it} = \beta_{0i} + \beta_{1i} \cdot \sum_{j=1}^{t} \gamma_i^{t-j} \cdot \text{PE}_{\text{pos},j} + \beta_{2i} \cdot \sum_{j=1}^{t} \gamma_i^{t-j} \cdot \text{PE}_{\text{neg},j} + \beta_{3i} \cdot O_t + \beta_{4i} \cdot M_i \\\text{Anxiety}_{it} = \beta_{0i} + \beta_{1i} \cdot \sum_{j=1}^{t} \gamma_i^{t-j} \cdot \text{PE}_{\text{pos},j} + \beta_{2i} \cdot \sum_{j=1}^{t} \gamma_i^{t-j} \cdot \text{PE}_{\text{neg},j} + \beta_{3i} \cdot O_t + \beta_{4} \cdot M_i \\\beta_{0i} = \mu_{\beta_0} + \beta_{0 \times M} \cdot M_i + \epsilon_{\beta_{0i}} \\\beta_{1i} = \mu_{\beta_1} + \beta_{1 \times M} \cdot M_i + \epsilon_{\beta_{1i}} \\\beta_{2i} = \mu_{\beta_2} + \beta_{2 \times M} \cdot M_i + \epsilon_{\beta_{2i}} \\\beta_{3i} = \mu_{\beta_3} + \beta_{3 \times M} \cdot M_i + \epsilon_{\beta_{3i}} \\\gamma_i = \Phi\left(\mu_{\gamma} + \beta_{\gamma \times M} \cdot M_i + \epsilon_{\gamma_i} \right) \\\sigma_i = \exp\left(\mu_{\sigma} + \beta_{\sigma \times M} \cdot M_i + \epsilon_{\sigma_i} \right)\end{gather*}
$$

where $\epsilon_{\theta i} \sim \mathcal{N}(0, \sigma_{\theta}^2)$ are individual-level deviations.

to be added:

-   (in methods) Paragraph on transparency (will create gorilla links where people can preview experiment ;e.g. <https://app.gorilla.sc/openmaterials/1080493> (will need to publish)

## References

