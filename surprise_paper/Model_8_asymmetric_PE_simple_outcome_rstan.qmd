---
title: "Model_7_asymmetric_PE_simple_outcome_rstan"
format: html
editor: visual
---

## Asymmetric PEs and outcome model

In this model, anxiety/mood on trial $t$ is calculated by adding the intercept $\beta_0$ (the value of anxiety/mood when $W_{1t}$ and $W_{2t}$ are set to 0), a weighted cumulative PE and a weighted cumulative expectation on trial $t$.

The term $\gamma^{(t - j)}$ decreases as $j$ becomes smaller relative to $t$. This means that PE and expectations closer to the current trial $t$ have larger weights, while PE and expectations further in the past have smaller weights. The exponential function ensures that PE and expectations further back in time are **"discounted" exponentially**. This is a type of **recency** **model**.

$$
A_t = \beta_0 +\beta_1\cdot  \sum_{j=1}^{t} \gamma^{t - j} \cdot PE_{pos}(j) + \beta_2\cdot \sum_{j=1}^{t} \gamma^{t - j} \cdot PE_{neg}(j)  + \beta_3\cdot O(t)\
$$

$$
M_t =\beta_0 +\beta_1\cdot  \sum_{j=1}^{t} \gamma^{t - j} \cdot PE_{pos}(j) + \beta_2\cdot \sum_{j=1}^{t} \gamma^{t - j} \cdot PE_{neg}(j)  + \beta_3\cdot O(t)\
$$

```{r}

########################################## For Anxiety ########################################
library(rstan)
library(dplyr)
library(ggplot2)

# Load Data
data <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/surprise_task_merged_data.csv")
  

# Scale all relevant variables
data$Response_SubjPE_scaled <- scale(data$Response_SubjPE)[, 1]
data$Response_fdbk <- scale(data$Response_fdbk)[, 1]
data$Response_Ax <- scale(data$Response_Ax)[, 1]

# Recalculate positive and negative PEs using original (unscaled) sign
data$Response_PosPE <- ifelse(data$Response_SubjPE > 0, data$Response_SubjPE_scaled, 0)
data$Response_NegPE <- ifelse(data$Response_SubjPE < 0, data$Response_SubjPE_scaled, 0)

N <- length(unique(data$Random_ID))  # Number of participants
T <- 48  # Trials per participant

stan_data <- list(
  N = N,
  T = T,
  Tsubj = rep(48, N),
  Response_fdbk = matrix(data$Response_fdbk, nrow = N, ncol = T, byrow = TRUE),
  Response_Ax = matrix(data$Response_Ax, nrow = N, ncol = T, byrow = TRUE),
  Response_PosPE = matrix(data$Response_PosPE, nrow = N, ncol = T, byrow = TRUE),
  Response_NegPE = matrix(data$Response_NegPE, nrow = N, ncol = T, byrow = TRUE)
)



# Stan Model
asymmPE_simple_Outcome_anx <- "data {
  int<lower=1> N;
  int<lower=1> T;
  int<lower=1, upper=T> Tsubj[N]; 
  array[N, T] real Response_fdbk;
  array[N, T] real Response_Ax;
  array[N, T] real Response_PosPE;
  array[N, T] real Response_NegPE;
}
parameters {
  real intercept;
  real w1_mu;
  real w_pos_mu;
  real w_neg_mu;
  real gam_mu;
  real sig_mu;

  real<lower=0> sigma_w0;
  vector<lower=0>[5] sigma;

  vector[N] w0_pr;
  vector[N] w1_pr;
  vector[N] w_pos_pr;
  vector[N] w_neg_pr;
  vector[N] gam_pr;
  vector[N] sig_pr;
}
transformed parameters {
  vector[N] w0;
  vector[N] w1;
  vector[N] w_pos;
  vector[N] w_neg;
  vector<lower=0, upper=1>[N] gam;
  vector<lower=0>[N] sig;

  w0 = intercept + sigma_w0 * w0_pr;
  w1 = w1_mu + sigma[1] * w1_pr;
  w_pos = w_pos_mu + sigma[2] * w_pos_pr;
  w_neg = w_neg_mu + sigma[3] * w_neg_pr;

  for (i in 1:N) {
    gam[i] = Phi_approx(gam_mu + sigma[4] * gam_pr[i]);
  }
  sig = exp(sig_mu + sigma[5] * sig_pr);
}
model {
  intercept ~ normal(0, 0.5);
  w1_mu ~ normal(0, 0.5);
  w_pos_mu ~ normal(0, 0.5);
  w_neg_mu ~ normal(0, 0.5);
  gam_mu ~ normal(0, 0.5);
  sig_mu ~ normal(0, 0.5);

  sigma_w0 ~ normal(0, 1);
  sigma ~ normal(0, 0.1);

  w0_pr ~ normal(0, 1);
  w1_pr ~ normal(0, 1);
  w_pos_pr ~ normal(0, 1);
  w_neg_pr ~ normal(0, 1);
  gam_pr ~ normal(0, 1);
  sig_pr ~ normal(0, 1);

  for (i in 1:N) {
    real pospe_sum = 0;
    real negpe_sum = 0;

    for (t in 1:Tsubj[i]) {
      Response_Ax[i, t] ~ normal(
        w0[i] + w1[i] * Response_fdbk[i, t] + w_pos[i] * pospe_sum + w_neg[i] * negpe_sum,
        sig[i]);

      pospe_sum += Response_PosPE[i, t];
      negpe_sum += Response_NegPE[i, t];

      pospe_sum *= gam[i];
      negpe_sum *= gam[i];
    }
  }
}
generated quantities {
  real mu_w0;
  real mu_w1;
  real mu_w_pos;
  real mu_w_neg;
  real<lower=0, upper=1> mu_gam;
  real<lower=0> mu_sig;

  real log_lik[N];
  real y_pred[N, T];

  mu_w0 = intercept;
  mu_w1 = w1_mu;
  mu_w_pos = w_pos_mu;
  mu_w_neg = w_neg_mu;
  mu_gam = Phi_approx(gam_mu);
  mu_sig = exp(sig_mu);

  for (i in 1:N) {
    real pospe_sum = 0;
    real negpe_sum = 0;
    log_lik[i] = 0;

    for (t in 1:Tsubj[i]) {
      real mu = w0[i] + w1[i] * Response_fdbk[i, t] + w_pos[i] * pospe_sum + w_neg[i] * negpe_sum;
      log_lik[i] += normal_lpdf(Response_Ax[i, t] | mu, sig[i]);
      y_pred[i, t] = normal_rng(mu, sig[i]);

      pospe_sum += Response_PosPE[i, t];
      negpe_sum += Response_NegPE[i, t];

      pospe_sum *= gam[i];
      negpe_sum *= gam[i];
    }
  }
}
"

```

```{r}

# Compile and Fit the Model
asymmPE_simple_Outcome_anx_fit <- stan(model_code = asymmPE_simple_Outcome_anx, data = stan_data, iter = 4000, warmup = 2000, chains = 4, seed = 123, cores = 4, control = list(adapt_delta = 0.95,
  max_treedepth = 10))

options(max.print = 99999)  # Set a higher limit

# Print results
print(asymmPE_simple_Outcome_anx_fit)

saveRDS(asymmPE_simple_Outcome_anx_fit, "asymmPE_simple_Outcome_anx_fit.rds")
```

```{r}

asymmPE_simple_Outcome_anx_fit<- readRDS("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/R code/Computational modelling/Full_scale_data_comp_modelling_results/asymmPE_simple_Outcome_anx_fit.rds")
# Plot results
traceplot(asymmPE_simple_Outcome_anx_fit)

# Extract posterior samples
posterior_samples <- rstan::extract(asymmPE_simple_Outcome_anx_fit)

library(ggplot2)
library(dplyr)
library(tidyr)


# 2. Calculate the estimated Response_Ax for each participant
# Generate the estimated Response_Ax from posterior predictive distribution
y_pred <- posterior_samples$y_pred


# Extract log-likelihood per participant (N-length vector)
log_lik_vector <- rstan::extract(asymmPE_simple_Outcome_anx_fit, pars = "log_lik")$log_lik  # Dimensions: [S, N] (S = posterior samples)

# Compute LOO-CV
library(loo)
loo_result <- loo(log_lik_vector)
print(loo_result)
dim(log_lik_vector)
library(loo)

# Compute WAIC
waic_result <- waic(log_lik_vector)
print(waic_result)



# Extract the posterior samples
posterior_samples <- rstan::extract(asymmPE_simple_Outcome_anx_fit)

# Predicted values (posterior predictive distribution)
y_pred <- posterior_samples$y_pred
# Load required package
library(matrixStats)

# Compute mean predicted values (posterior mean)
y_pred_mean <- apply(y_pred, c(2,3), mean)  # Mean across posterior samples

# Compute MSE
mse <- mean((y_pred_mean - stan_data$Response_Ax)^2)

# Compute MAE
mae <- mean(abs(y_pred_mean -  stan_data$Response_Ax))

print(paste("MSE:", mse))
print(paste("MAE:", mae))


y_pred_mean <- apply(posterior_samples$y_pred, c(2, 3), mean) 
y_pred_df <- as.data.frame(y_pred_mean)
colnames(y_pred_df) <- paste0("Trial_", 1:T)
y_pred_df$Random_ID <- unique(data$Random_ID)


# Convert Response_Ax to matrix and then to a data frame
Response_Ax_matrix <- matrix(data$Response_Ax, nrow = N, ncol = T, byrow = TRUE)
Response_Ax_df <- as.data.frame(Response_Ax_matrix)
colnames(Response_Ax_df) <- paste0("Trial_", 1:T)
Response_Ax_df$Random_ID <- unique(data$Random_ID)

# Reshape data into long format
y_pred_long <- pivot_longer(y_pred_df, cols = starts_with("Trial_"), names_to = "Trial", values_to = "Predicted_Response")
Response_Ax_long <- pivot_longer(Response_Ax_df, cols = starts_with("Trial_"), names_to = "Trial", values_to = "Actual_Response")

# Merge actual and predicted data
plot_data <- left_join(Response_Ax_long, y_pred_long, by = c("Random_ID", "Trial"))

# Convert Trial to numeric
plot_data$Trial <- as.numeric(gsub("Trial_", "", plot_data$Trial))



# Plot individual real data and fitted curve for each participant using ggplot2
ggplot(plot_data, aes(x = Trial)) +
  geom_line(aes(y = Actual_Response), color = "blue", size = 1) + 
  geom_line(aes(y = Predicted_Response), color = "red", size = 1) +
  facet_wrap(~ Random_ID, scales = "free_y") +
  labs(title = "Real Data and Fitted Curve per Participant",
       x = "Trial Number",
       y = "Anxiety") +
  ylim(-3,3)
  theme_minimal()

  
library(bayesplot)
y_obs <- stan_data$Response_Ax
# Select a subset of posterior draws for plotting
set.seed(123)
draws_to_plot <- sample(1:dim(y_pred)[1], 20)  # e.g. 20 random posterior draws
y_pred_subset <- y_pred[draws_to_plot,,]        # Subset of y_rep

# Flatten y_obs for histogram comparison
y_obs_flat <- as.vector(y_obs)

# Convert y_rep_subset into a matrix: draws x (N*T)
y_pred_matrix <- apply(y_pred_subset, 1, function(mat) as.vector(t(mat)))
y_pred_matrix <- t(y_pred_matrix)  # make it draws x obs

# Now plot
color_scheme_set("blue")
ppc_hist(y_obs_flat, y_pred_matrix[1:8, ])  # show 8 histograms for example

posterior<- rstan::extract(asymmPE_simple_Outcome_anx_fit)
hdi(posterior$w1_mu
    , ci = 0.95)
hdi(posterior$w_pos_mu
    , ci = 0.95)
hdi(posterior$w_neg_mu
    , ci = 0.95)
hdi(posterior$mu_gam
    , ci = 0.95)
hdi(posterior$sigma
    , ci = 0.95)

```

```{r}

asymmPE_simple_Outcome_anx_fit <- readRDS("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/R code/Computational modelling/Full_scale_data_comp_modelling_results/asymmPE_simple_Outcome_anx_fit.rds")

unique(plot_data$Random_ID)
plot_data_1_pt<- plot_data %>%
  group_by(Random_ID) %>%
  filter(Random_ID %in% c("SUPPRF60894"))

# Replace Random_IDs with readable labels
plot_data_1_pt$Random_ID <- recode(plot_data_1_pt$Random_ID,
                                    "SUPPRF60894" = "Participant 1")

# Reshape data for easier plotting with a legend
library(tidyr)
plot_long <- plot_data_1_pt %>%
  pivot_longer(cols = c(Actual_Response, Predicted_Response),
               names_to = "Type",
               values_to = "Anxiety")
ggplot(plot_long, aes(x = Trial, y = Anxiety, color = Type)) +
  geom_line(size = 1.5) + 
  facet_wrap(~ Random_ID, scales = "free_y") +
  scale_color_manual(
    values = c(
      "Actual_Response" = "#FF9999",   # Light orange
      "Predicted_Response" = "red"     # Dark orange
    ),
    labels = c("Reported Anxiety", "Predicted Anxiety"),
    name = ""
  ) +
  labs(
    title = "Real Data and Fitted Curve per Participant",
    x = "Trial Number",
    y = "Anxiety"
  ) +
  ylim(-3, 3) +
  theme_minimal(base_size = 18) +
  theme(
    legend.position = c(0.85, 0.15),        # Legend inside the plot (x, y from bottom-left)
    legend.background = element_rect(fill = "white", "white"),  # Optional: improve readability
    panel.grid.major = element_line(size = 0.2),
    panel.grid.minor = element_blank()
  )

```

```{r}
########################################## For Mood ########################################
library(rstan)
library(dplyr)
library(ggplot2)

# Load Data
data <- read.csv("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/GitHub/aim_lab_1/Surprise_task_data_analysis/surprise_task_merged_data.csv")


# Scale all relevant variables
data$Response_SubjPE_scaled <- scale(data$Response_SubjPE)[, 1]
data$Response_fdbk <- scale(data$Response_fdbk)[, 1]
data$Response_H <- scale(data$Response_H)[, 1]

# Recalculate positive and negative PEs using original (unscaled) sign
data$Response_PosPE <- ifelse(data$Response_SubjPE > 0, data$Response_SubjPE_scaled, 0)
data$Response_NegPE <- ifelse(data$Response_SubjPE < 0, data$Response_SubjPE_scaled, 0)
  
N <- length(unique(data$Random_ID))  # Number of participants
T <- 48  # Trials per participant

stan_data <- list(
  N = N,
  T = T,
  Tsubj = rep(48, N),
  Response_fdbk = matrix(data$Response_fdbk, nrow = N, ncol = T, byrow = TRUE),
  Response_H = matrix(data$Response_H, nrow = N, ncol = T, byrow = TRUE),
  Response_PosPE = matrix(data$Response_PosPE, nrow = N, ncol = T, byrow = TRUE),
  Response_NegPE = matrix(data$Response_NegPE, nrow = N, ncol = T, byrow = TRUE)
)



# Stan Model
asymmPE_simple_Outcome_mood <- "data {
  int<lower=1> N;
  int<lower=1> T;
  int<lower=1, upper=T> Tsubj[N]; 
  array[N, T] real Response_fdbk;
  array[N, T] real Response_H;
  array[N, T] real Response_PosPE;
  array[N, T] real Response_NegPE;
}
parameters {
  real intercept;
  real w1_mu;
  real w_pos_mu;
  real w_neg_mu;
  real gam_mu;
  real sig_mu;

  real<lower=0> sigma_w0;
  vector<lower=0>[5] sigma;

  vector[N] w0_pr;
  vector[N] w1_pr;
  vector[N] w_pos_pr;
  vector[N] w_neg_pr;
  vector[N] gam_pr;
  vector[N] sig_pr;
}
transformed parameters {
  vector[N] w0;
  vector[N] w1;
  vector[N] w_pos;
  vector[N] w_neg;
  vector<lower=0, upper=1>[N] gam;
  vector<lower=0>[N] sig;

  w0 = intercept + sigma_w0 * w0_pr;
  w1 = w1_mu + sigma[1] * w1_pr;
  w_pos = w_pos_mu + sigma[2] * w_pos_pr;
  w_neg = w_neg_mu + sigma[3] * w_neg_pr;

  for (i in 1:N) {
    gam[i] = Phi_approx(gam_mu + sigma[4] * gam_pr[i]);
  }
  sig = exp(sig_mu + sigma[5] * sig_pr);
}
model {
  intercept ~ normal(0, 0.5);
  w1_mu ~ normal(0, 0.5);
  w_pos_mu ~ normal(0, 0.5);
  w_neg_mu ~ normal(0, 0.5);
  gam_mu ~ normal(0, 0.5);
  sig_mu ~ normal(0, 0.5);

  sigma_w0 ~ normal(0, 1);
  sigma ~ normal(0, 0.1);

  w0_pr ~ normal(0, 1);
  w1_pr ~ normal(0, 1);
  w_pos_pr ~ normal(0, 1);
  w_neg_pr ~ normal(0, 1);
  gam_pr ~ normal(0, 1);
  sig_pr ~ normal(0, 1);

  for (i in 1:N) {
    real pospe_sum = 0;
    real negpe_sum = 0;

    for (t in 1:Tsubj[i]) {
      Response_H[i, t] ~ normal(
        w0[i] + w1[i] * Response_fdbk[i, t] + w_pos[i] * pospe_sum + w_neg[i] * negpe_sum,
        sig[i]);

      pospe_sum += Response_PosPE[i, t];
      negpe_sum += Response_NegPE[i, t];

      pospe_sum *= gam[i];
      negpe_sum *= gam[i];
    }
  }
}
generated quantities {
  real mu_w0;
  real mu_w1;
  real mu_w_pos;
  real mu_w_neg;
  real<lower=0, upper=1> mu_gam;
  real<lower=0> mu_sig;

  real log_lik[N];
  real y_pred[N, T];

  mu_w0 = intercept;
  mu_w1 = w1_mu;
  mu_w_pos = w_pos_mu;
  mu_w_neg = w_neg_mu;
  mu_gam = Phi_approx(gam_mu);
  mu_sig = exp(sig_mu);

  for (i in 1:N) {
    real pospe_sum = 0;
    real negpe_sum = 0;
    log_lik[i] = 0;

    for (t in 1:Tsubj[i]) {
      real mu = w0[i] + w1[i] * Response_fdbk[i, t] + w_pos[i] * pospe_sum + w_neg[i] * negpe_sum;
      log_lik[i] += normal_lpdf(Response_H[i, t] | mu, sig[i]);
      y_pred[i, t] = normal_rng(mu, sig[i]);

      pospe_sum += Response_PosPE[i, t];
      negpe_sum += Response_NegPE[i, t];

      pospe_sum *= gam[i];
      negpe_sum *= gam[i];
    }
  }
}
"
```

```{r}

# Compile and Fit the Model
asymmPE_simple_Outcome_mood_fit <- stan(model_code = asymmPE_simple_Outcome_mood, data = stan_data, iter = 4000, warmup = 2000, chains = 4, seed = 123, cores = 4, control = list(adapt_delta = 0.95,
  max_treedepth = 10))

options(max.print = 9999)  # Set a higher limit

# Print results
print(asymmPE_simple_Outcome_mood_fit)

saveRDS(asymmPE_simple_Outcome_mood_fit, "asymmPE_simple_Outcome_mood_fit.rds")
```

```{r}
# Plot results
traceplot(asymmPE_simple_Outcome_mood_fit)

# Extract posterior samples
posterior_samples <- rstan::extract(asymmPE_simple_Outcome_mood_fit)

library(ggplot2)
library(dplyr)
library(tidyr)


# 2. Calculate the estimated Response_Ax for each participant
# Generate the estimated Response_Ax from posterior predictive distribution
y_pred <- posterior_samples$y_pred


# Extract log-likelihood per participant (N-length vector)
log_lik_vector <- rstan::extract(asymmPE_simple_Outcome_mood_fit, pars = "log_lik")$log_lik  # Dimensions: [S, N] (S = posterior samples)

# Compute LOO-CV
library(loo)
loo_result <- loo(log_lik_vector)
print(loo_result)
dim(log_lik_vector)
library(loo)

# Compute WAIC
waic_result <- waic(log_lik_vector)
print(waic_result)



# Extract the posterior samples
posterior_samples <- rstan::extract(asymmPE_simple_Outcome_mood_fit)

# Predicted values (posterior predictive distribution)
y_pred <- posterior_samples$y_pred
# Load required package
library(matrixStats)

# Compute mean predicted values (posterior mean)
y_pred_mean <- apply(y_pred, c(2,3), mean)  # Mean across posterior samples

# Compute MSE
mse <- mean((y_pred_mean - stan_data$Response_H)^2)

# Compute MAE
mae <- mean(abs(y_pred_mean -  stan_data$Response_H))

print(paste("MSE:", mse))
print(paste("MAE:", mae))


y_pred_mean <- apply(posterior_samples$y_pred, c(2, 3), mean) 
y_pred_df <- as.data.frame(y_pred_mean)
colnames(y_pred_df) <- paste0("Trial_", 1:T)
y_pred_df$Random_ID <- unique(data$Random_ID)


# Convert Response_Ax to matrix and then to a data frame
Response_H_matrix <- matrix(data$Response_H, nrow = N, ncol = T, byrow = TRUE)
Response_H_df <- as.data.frame(Response_H_matrix)
colnames(Response_H_df) <- paste0("Trial_", 1:T)
Response_H_df$Random_ID <- unique(data$Random_ID)

# Reshape data into long format
y_pred_long <- pivot_longer(y_pred_df, cols = starts_with("Trial_"), names_to = "Trial", values_to = "Predicted_Response")
Response_H_long <- pivot_longer(Response_H_df, cols = starts_with("Trial_"), names_to = "Trial", values_to = "Actual_Response")

# Merge actual and predicted data
plot_data <- left_join(Response_H_long, y_pred_long, by = c("Random_ID", "Trial"))

# Convert Trial to numeric
plot_data$Trial <- as.numeric(gsub("Trial_", "", plot_data$Trial))



# Plot individual real data and fitted curve for each participant using ggplot2
ggplot(plot_data, aes(x = Trial)) +
  geom_line(aes(y = Actual_Response), color = "blue", size = 1) + 
  geom_line(aes(y = Predicted_Response), color = "red", size = 1) +
  facet_wrap(~ Random_ID, scales = "free_y") +
  labs(title = "Real Data and Fitted Curve per Participant",
       x = "Trial Number",
       y = "Mood") +
  ylim(-3,3)
  theme_minimal()

  
library(bayesplot)
y_obs <- stan_data$Response_H
# Select a subset of posterior draws for plotting
set.seed(123)
draws_to_plot <- sample(1:dim(y_pred)[1], 20)  # e.g. 20 random posterior draws
y_pred_subset <- y_pred[draws_to_plot,,]        # Subset of y_rep

# Flatten y_obs for histogram comparison
y_obs_flat <- as.vector(y_obs)

# Convert y_rep_subset into a matrix: draws x (N*T)
y_pred_matrix <- apply(y_pred_subset, 1, function(mat) as.vector(t(mat)))
y_pred_matrix <- t(y_pred_matrix)  # make it draws x obs

# Now plot
color_scheme_set("blue")
ppc_hist(y_obs_flat, y_pred_matrix[1:8, ])  # show 8 histograms for example



library(bayestestR)

posterior <- rstan::extract(asymmPE_simple_Outcome_mood_fit)
hdi(posterior$w1_mu
    , ci = 0.95)
hdi(posterior$w_pos_mu
    , ci = 0.95)
hdi(posterior$w_neg_mu
    , ci = 0.95)
hdi(posterior$mu_gam
    , ci = 0.95)
hdi(posterior$sigma
    , ci = 0.95)
```

```{r}

asymmPE_simple_Outcome_mood_fit <- readRDS("/Users/elenabagdades/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Desktop/R code/Computational modelling/Full_scale_data_comp_modelling_results/asymmPE_simple_Outcome_mood_fit.rds")


unique(plot_data$Random_ID)
plot_data_1_pt<- plot_data %>%
  group_by(Random_ID) %>%
  filter(Random_ID %in% c("SUPPRF60894"))

# Replace Random_IDs with readable labels
plot_data_1_pt$Random_ID <- recode(plot_data_1_pt$Random_ID,
                                    "SUPPRF60894" = "Participant 1")

# Reshape data for easier plotting with a legend
library(tidyr)
plot_long_mood <- plot_data_1_pt %>%
  pivot_longer(cols = c(Actual_Response, Predicted_Response),
               names_to = "Type",
               values_to = "Mood")


ggplot(plot_long_mood, aes(x = Trial, y = Mood, color = Type)) +
  geom_line(size = 1.5) + 
  facet_wrap(~ Random_ID, scales = "free_y") +
  scale_color_manual(
    values = c(
      "Actual_Response" = "#FDBF6F",   # Light orange
      "Predicted_Response" = "#FF7F00"     # Dark orange
    ),
    labels = c("Reported Mood", "Predicted Mood"),
    name = ""
  ) +
  labs(
    title = "Real Data and Fitted Curve per Participant",
    x = "Trial Number",
    y = "Mood"
  ) +
  ylim(-3, 3) +
  theme_minimal(base_size = 18) +
  theme(
    legend.position = c(0.85, 0.15),        # Legend inside the plot (x, y from bottom-left)
    legend.background = element_rect(fill = "white", "white"),  # Optional: improve readability
        legend.spacing.y = unit(1, "lines"),   # Reduce vertical spacing between items
    panel.grid.major = element_line(size = 0.2),
    panel.grid.minor = element_blank()
  )


```

```{r}
plot_long_mood$Measure <- "Mood"
plot_long$Measure <- "Anxiety"

plot_long_combined_long <- plot_long_combined %>%
  pivot_longer(
    cols = c(Mood, Anxiety),
    names_to = "Score_Type",
    values_to = "Score"
  ) %>%
  filter(!is.na(Score)) %>%
  mutate(
    Response_Label = case_when(
      Measure == "Mood" & Type == "Actual_Response" ~ "Mood - Reported",
      Measure == "Mood" & Type == "Predicted_Response" ~ "Mood - Predicted",
      Measure == "Anxiety" & Type == "Actual_Response" ~ "Anxiety - Reported",
      Measure == "Anxiety" & Type == "Predicted_Response" ~ "Anxiety - Predicted"
    ),
    # Set the order so that predicted lines are drawn last (on top)
    Response_Label = factor(Response_Label, levels = c(
      "Mood - Reported", "Anxiety - Reported",
      "Mood - Predicted", "Anxiety - Predicted"
    ))
  )


ggplot(plot_long_combined_long, aes(x = Trial, y = Score, color = Response_Label)) +
  geom_line(size = 1.5) +
  facet_grid(Random_ID ~ Measure, scales = "free_y") +
  scale_color_manual(
    values = c(
      "Mood - Reported" = "#FDBF6F",       # Light orange
      "Mood - Predicted" = "#FF7F00",      # Dark orange
      "Anxiety - Reported" = "#FF9999",    # Light red
      "Anxiety - Predicted" = "red"        # Red
    ),
    name = "Response Type"
  ) +
  labs(
    title = "Reported and Predicted Mood and Anxiety per Participant",
    x = "Trial Number",
    y = "Score"
  ) +
  ylim(-3, 3) +
  theme_minimal(base_size = 18)+  # base size for most elements
theme(
  legend.title = element_text(size = 20),   # key title
  legend.text = element_text(size = 18),    # key labels
  strip.text = element_text(size = 18),     # facet labels
  axis.title = element_text(size = 18),     # axis titles
  axis.text = element_text(size = 16),      # axis tick labels
  plot.title = element_text(size = 22, face = "bold")  # plot title
)


```
